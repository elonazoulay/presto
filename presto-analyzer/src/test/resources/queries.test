atn3_batch2	prism_batch	bi	20180315_150112_43887_y3fk21	dataswarm@worker@bi.cde.recommendations_framework.TipGenerator.execute[me_leadgen_use_lookalike_audiences][create_rec]	select lineitem.orderkey, lineitem.quantity, orders.totalprice, orders.orderkey from lineitem join orders using (orderkey)\n
atn3_batch2	prism_batch	bi	20180315_150112_43887_y3fk2	dataswarm@worker@bi.cde.recommendations_framework.TipGenerator.execute[me_leadgen_use_lookalike_audiences][create_rec]	/* Generated */\nINSERT INTO fct_crm_tip_gen_create_rec (\n  "key",\n  "key_type",\n  "data",\n  "ds",\n  "recommendation"\n)\nSELECT\n  "key",\n  "key_type",\n  "data",\n  '2018-03-15' AS "ds",\n  'me_leadgen_use_lookalike_audiences' AS "recommendation"\nFROM (\n  /* User-provided */\n  WITH valid_ca AS (\n      SELECT\n          account_id AS ad_account_id\n      FROM\n          all_ads_details\n      WHERE\n          ds = '2018-03-13'\n          AND is_56_day_active = 1\n      GROUP BY account_id\n      HAVING\n          SUM(tgt_custom_audience_inc_ind\n              + tgt_custom_audience_wca_ind\n              + tgt_custom_audience_maca_ind\n              + tgt_custom_audience_mca_ind\n              + tgt_custom_audience_dataset_ind)\n          > 0\n  ),\n  enough_pixel AS (\n      SELECT DISTINCT\n          ad_account_id\n      FROM\n          dim_account_pixel_status:ad_metrics\n      WHERE\n          ds = '2018-03-13'\n          AND ad_account_id != 0\n          AND ad_account_id IS NOT NULL\n          AND fired_fp_28d >= 100\n  ),\n  engaged_fans AS (\n      SELECT DISTINCT\n          account_id AS ad_account_id\n      FROM\n          pages_normalized_reach_engagement:pageinsights pnre\n      JOIN\n          dim_ad_account_page daap\n      ON\n          daap.page_id = pnre.page_id\n          AND daap.ds = '2018-03-13'\n          AND pnre.ds = '2018-03-13'\n          AND pnre.fan_count > 1000\n          AND pnre.engagement_per_fan > 0.8\n  ),\n  not_using_lookalikes AS (\n      SELECT\n          account_id AS ad_account_id\n      FROM\n          all_ads_details\n      WHERE\n          ds = '2018-03-13'\n          AND is_56_day_active = 1\n      GROUP BY account_id\n      HAVING\n          SUM(tgt_custom_audience_lkl_ind\n              + tgt_lkl_datafiles_ind\n              + tgt_lkl_wca_ind\n              + tgt_lkl_pixel_ind\n              + tgt_lkl_maca_ind\n              + tgt_lkl_app_ind\n              + tgt_lkl_mca_ind\n              + tgt_lkl_pagefan_ind\n              + tgt_lkl_dataset_ind)\n          = 0\n  )\n  SELECT\n      a.ad_account_id as key\n      ,804 as key_type\n      ,MAP(\n          ARRAY[\n              'related_ids',\n              'impact_estimate'\n          ],\n          ARRAY[\n              ARRAY_JOIN(ARRAY_AGG(a.ad_account_id),','),\n              TRY_CAST(SUM(rev.revenue_28) as VARCHAR)\n          ]\n      ) as data\n  FROM (\n      SELECT\n          isnt.ad_account_id\n      FROM\n          not_using_lookalikes isnt\n      JOIN (\n          SELECT\n              ad_account_id\n          FROM\n              valid_ca\n\n          UNION\n\n          SELECT\n              ad_account_id\n          FROM\n              enough_pixel\n\n          UNION\n\n          SELECT\n              ad_account_id\n          FROM\n              engaged_fans\n      ) should\n      ON\n          isnt.ad_account_id = should.ad_account_id\n  ) a\n  JOIN (\n      SELECT\n          key AS ad_account_id\n          ,TRY_CAST(metrics['legal_budget_28d'] AS DOUBLE)\n              AS revenue_28\n      FROM fct_crm_rec_collect_metrics\n      WHERE\n          ds = '2018-03-14'\n          AND key_type = '804'\n          AND TRY_CAST(metrics['legal_budget_28d'] AS DOUBLE) > 0\n  ) rev\n  ON rev.ad_account_id = a.ad_account_id\n  GROUP BY a.ad_account_id\n)
atn2_batch1	prism_batch	messages	20180326_080527_07209_jax9y	dataswarm@worker@messages.tincan.reliability.messages_sent_and_acked_from_server.main_query	/* Generated */\nINSERT INTO tincan_message_sends_and_acks (\n  "appid",\n  "userid",\n  "extra",\n  "deviceid",\n  "appversion",\n  "clienttime",\n  "containermodule",\n  "carrier",\n  "country",\n  "isemployee",\n  "msg_id",\n  "client_timestamp_ms",\n  "major_app_version",\n  "ack_latency",\n  "ack_failure_reason",\n  "ack_client_timestamp",\n  "ack_name",\n  "ack_extra",\n  "ds"\n)\nSELECT\n  "appid",\n  "userid",\n  "extra",\n  "deviceid",\n  "appversion",\n  "clienttime",\n  "containermodule",\n  "carrier",\n  "country",\n  "isemployee",\n  "msg_id",\n  "client_timestamp_ms",\n  "major_app_version",\n  "ack_latency",\n  "ack_failure_reason",\n  "ack_client_timestamp",\n  "ack_name",\n  "ack_extra",\n  '2018-03-24' AS "ds"\nFROM (\n  /* User-provided */\n  WITH\n     -- Subtable with all the send message events and the fields we are\n     -- interested in. This is just for convenience to perform the\n     -- query after this one\n     message_send_events AS(\n      SELECT\n          appid,\n          userid,\n          extra,\n          deviceid,\n          appversion,\n          clienttime,\n          containermodule,\n          carrier,\n          country,\n          isemployee,\n          JSON_EXTRACT_SCALAR(extra, '$.msg_id') AS msg_id,\n          CAST(JSON_EXTRACT_SCALAR(extra, '$.client_timestamp_ms') AS bigint) AS client_timestamp_ms\n      FROM\n          honey_hces_messages\n      WHERE\n          ds = '2018-03-24'\n          AND\n          name = 'tincan_msg_send_attempt'\n          AND\n          REGEXP_EXTRACT(appversion, '([0-9]+)(\\.[0-9]+)*' , 1) >= '130'  --D5484791\n  ),\n    -- Subtable that sorts message send events by timestamp and associates\n    -- a "rank" with them (sequencial number from 1 to N ordered by\n    -- timestamp and grouped by message ID. This rank is used to join\n    -- these rows with the ACKs from the server). For instance:\n    --\n    -- msg_id     timestamp   rank\n    -- 1          100         1\n    -- 1          110         2\n    -- 1          120         3\n    -- 2          34          1\n    -- 2          44          2\n    -- ...\n    messages_sent_ranked AS (\n      SELECT\n          *,\n          ROW_NUMBER() OVER (PARTITION BY userid, msg_id ORDER BY client_timestamp_ms) AS rank\n      FROM\n          message_send_events\n  ),\n    -- This is the list of ACKs that we got for the messages that were\n    -- sent on DATEID. To account for messages whose ACKs might be delayed\n    -- or messages that are sent at the end of DATEID (and whose ACKs\n    -- would come on DATEID+1), we look for ACKs on both DATEID and\n    -- DATEID+1\n    message_acks AS (\n      SELECT\n          userid,\n          JSON_EXTRACT_SCALAR(extra, '$.msg_id') AS msg_id,\n          CAST(JSON_EXTRACT_SCALAR(extra, '$.client_timestamp_ms') AS bigint) AS client_timestamp_ms,\n          name,\n          CAST(JSON_EXTRACT_SCALAR(extra, '$.sub_type') AS integer) AS failure_reason,\n          extra\n      FROM\n          honey_hces_messages\n      WHERE\n          ds IN ('2018-03-24', '2018-03-25')\n          AND(\n              -- An ACK for a Tincan send is either a\n              -- 'tincan_msg_send' event with success == 1 OR with\n              -- success == 0 and sub_type error code 0, 5 or 2, 11, 9, 13\n              -- Other error codes don't come from Tincan ACKs, so we\n              -- cannot include them here\n                  (\n                      name = 'tincan_msg_send'\n                      AND\n                      JSON_EXTRACT_SCALAR(extra, '$.success') = '1'\n                  )\n              OR (\n                      name = 'tincan_msg_send'\n                      AND\n                      JSON_EXTRACT_SCALAR(extra, '$.success') = '0'\n                      AND\n                      JSON_EXTRACT_SCALAR(extra, '$.sub_type') IN ('0', '5', '2', '11', '9', '13')\n                  )\n          )\n          AND\n          JSON_EXTRACT_SCALAR(extra, '$.msg_id') IN (\n              SELECT msg_id FROM message_send_events\n          )\n          AND\n          REGEXP_EXTRACT(appversion, '([0-9]+)(\\.[0-9]+)*' , 1) >= '130'\n  ),\n   -- Here we do the same as with message sends, and create a table where\n   -- we put all the ACKs with a 'rank'. It is this rank that allows us to\n   -- join both sets of data\n   message_acks_ranked AS (\n      SELECT\n          *,\n          ROW_NUMBER() OVER (PARTITION BY userid, msg_id ORDER BY client_timestamp_ms) AS rank\n      FROM\n          message_acks\n  )\n\n  -- Final query. This left joins the message sends with the message acks\n  -- by message ID and rank. Using the rank allows us to deal with\n  -- messages that are sent more than once since this allows us to know\n  -- which send attempt should be joined with which send ack.\n  -- The resulting table is such that those rows that have "send data"\n  -- but no "ack data" represent send attemtps that were not acked by\n  -- the server. Those rows that have "send data" and "ack data" represent\n  -- send attempts that were acked by the server\n  SELECT\n      ms.*,\n      REGEXP_EXTRACT(appversion, '([0-9]+)(\\.[0-9]+)*' , 1) AS major_app_version,\n      IF(ma.client_timestamp_ms IS NOT NULL, ma.client_timestamp_ms - ms.client_timestamp_ms, 0) AS ack_latency,\n      ma.failure_reason AS ack_failure_reason,\n      ma.client_timestamp_ms AS ack_client_timestamp,\n      ma.name AS ack_name,\n      ma.extra AS ack_extra\n  FROM\n      messages_sent_ranked AS ms\n      LEFT JOIN\n      message_acks_ranked AS ma\n      ON\n      ms.msg_id = ma.msg_id\n      AND\n      ms.rank = ma.rank\n      AND\n      ms.userid = ma.userid\n)
boron	prism	messages	20180329_210704_87581_7bwvd	unidash:302352623601210:argus:481124	-- Agent displays & clicks per message by country, also with CTR by country to support personalization threshold decisions\n\nWITH m_metrics AS\n(\nselect ds, agent, ip_country AS country,\nctr, bar_displays, clickers, bar_displayers, 1. * clicks_any_on_bar / bar_displays ctr_any_on_bar\n\nfrom omni_m_agent_metrics\nwhere ds = '2018-03-27'\nand ip_country IS NOT NULL\nand device_os IS NULL\nand locale IS NULL\nand agent = 'OmniMPaymentAgent'\nand ip_country IN ('US', 'MX', 'BR', 'CA', 'GB', 'FR', 'PT', 'ES', 'AU', 'TH')\n),\n\nmsgr_metrics AS\n(\n    SELECT ds, country, sum(metric_value) as message_sends, sum(unique_user_count) as message_senders\n    FROM core_metrics_summary:bi\n    WHERE (\n        ds = '2018-03-27'\n        AND app_type IN ('messenger')\n        AND aggregation_level = 'app_type'\n        AND metric_name = 'message_sends'\n    )\n    GROUP BY ds, country\n)\n\nselect 100. * bar_displays / message_sends AS displays_per_send\n, 100. * IF('agent_only'='any_on_bar', ctr_any_on_bar, ctr) AS ctr\n, m.country \nfrom m_metrics m\nleft join msgr_metrics msgr\nusing (ds, country)\norder by m.country desc
carbon_batch	prism_batch	operations	20180331_130800_40763_di6ar	dataswarm@worker@operations.co_quality.co_qa_all_samples_ramps.weekly_ramps_plus_50_supplemental_samples	/* Generated */\nINSERT INTO co_qa_all_samples_ramps (\n  "coalesced_user_id",\n  "person_type",\n  "employee_type",\n  "organization",\n  "work_city",\n  "ramp",\n  "ramps",\n  "market_reporting",\n  "market_group",\n  "vertical",\n  "sub_vertical",\n  "report_type",\n  "review_system",\n  "queue_fbid",\n  "queue_name",\n  "queue_group",\n  "report_intensity",\n  "action_severity",\n  "sigma_policy",\n  "content_id",\n  "identifier",\n  "srt_decision_id",\n  "close_event_time",\n  "srt_time_responded",\n  "is_gt_sample",\n  "source",\n  "mode",\n  "ds",\n  "partition_ds"\n)\nSELECT\n  "coalesced_user_id",\n  "person_type",\n  "employee_type",\n  "organization",\n  "work_city",\n  "ramp",\n  "ramps",\n  "market_reporting",\n  "market_group",\n  "vertical",\n  "sub_vertical",\n  "report_type",\n  "review_system",\n  "queue_fbid",\n  "queue_name",\n  "queue_group",\n  "report_intensity",\n  "action_severity",\n  "sigma_policy",\n  "content_id",\n  "identifier",\n  "srt_decision_id",\n  "close_event_time",\n  "srt_time_responded",\n  "is_gt_sample",\n  "source",\n  "mode",\n  '2018-03-30' AS "ds",\n  'weekly' AS "partition_ds"\nFROM (\n  /* User-provided */\n  WITH decisions AS (\n\n\n  SELECT DISTINCT\n      b.ds,\n      b.coalesced_user_id,\n      b.report_type,\n      b.organization,\n      b.employee_type,\n      COALESCE (\n        b.report_intensity_review,\n        b.report_intensity_close\n      ) AS report_intensity,\n      COALESCE (\n        b.action_severity_review,\n        b.action_severity_close\n      ) AS action_severity,\n      COALESCE (\n        b.market_group_review,\n        b.market_group_close\n      ) AS market_group,\n      b.person_type,\n      COALESCE(\n          b.review_queue_fbid,\n          b.close_queue_fbid\n      ) AS queue_fbid,\n      COALESCE(\n          b.review_queue_name,\n          b.close_queue_name\n      ) AS queue_name,\n      b.close_system AS review_system,\n      COALESCE(\n          b.review_market_reporting,\n          b.close_market_reporting\n      ) AS market_reporting,\n      COALESCE(\n          b.review_vertical,\n          b.close_vertical\n      ) AS vertical,\n      b.work_city,\n      COALESCE(\n          b.review_sub_vertical,\n          b.close_sub_vertical\n      ) AS sub_vertical,\n      b.sigma_policy,\n      b.object_id AS content_id,\n      b.job_id AS identifier,\n      b.srt_decision_id,\n      b.close_event_time,\n      b.time_responded AS srt_time_responded,\n      COALESCE (\n          b.review_queue_group,\n          b.close_queue_group\n      ) AS queue_group,\n      b.is_copac_ramp,\n      COALESCE (\n          b.ramp_review,\n          b.ramp_close\n      ) AS ramp,\n      COALESCE (\n          b.ramps_review,\n          b.ramps_close\n      ) AS ramps,\n      COALESCE(\n          b.high_severity_ind_review,\n          b.high_severity_ind_close\n      ) AS high_severity_ind,\n      b.is_gt_sample,\n      b.source,\n      b.has_content_deleted\n\n  FROM co_qa_all_decisions_ramps b\n\n\n      JOIN (\n          SELECT DISTINCT\n              object_id,\n              close_system,\n              MAX(close_event_time) AS close_event_time\n          FROM co_qa_all_decisions_ramps\n          WHERE ds= '2018-03-30'\n              AND partition_ds ='weekly'\n              AND review_system IN ('CRT','TPS')\n          GROUP BY\n              object_id,\n              close_system\n      ) a\n\n      ON a.object_id = b.object_id\n          AND a.close_event_time = b.close_event_time\n          AND a.close_system = b.close_system\n\n      WHERE b.close_system IN ('CRT', 'TPS')\n          AND b.ds = '2018-03-30'\n          AND b.partition_ds = 'weekly'\n          AND has_past_quality_job = false\n\n      UNION ALL\n\n\n  SELECT DISTINCT\n      b.ds,\n      b.coalesced_user_id,\n      b.report_type,\n      b.organization,\n      b.employee_type,\n      COALESCE (\n        b.report_intensity_review,\n        b.report_intensity_close\n      ) AS report_intensity,\n      COALESCE (\n        b.action_severity_review,\n        b.action_severity_close\n      ) AS action_severity,\n      COALESCE (\n        b.market_group_review,\n        b.market_group_close\n      ) AS market_group,\n      b.person_type,\n      COALESCE(\n          b.review_queue_fbid,\n          b.close_queue_fbid\n      ) AS queue_fbid,\n      COALESCE(\n          b.review_queue_name,\n          b.close_queue_name\n      ) AS queue_name,\n      b.close_system AS review_system,\n      COALESCE(\n          b.review_market_reporting,\n          b.close_market_reporting\n      ) AS market_reporting,\n      COALESCE(\n          b.review_vertical,\n          b.close_vertical\n      ) AS vertical,\n      b.work_city,\n      COALESCE(\n          b.review_sub_vertical,\n          b.close_sub_vertical\n      ) AS sub_vertical,\n      b.sigma_policy,\n      b.object_id AS content_id,\n      b.job_id AS identifier,\n      b.srt_decision_id,\n      b.close_event_time,\n      b.time_responded AS srt_time_responded,\n      COALESCE (\n          b.review_queue_group,\n          b.close_queue_group\n      ) AS queue_group,\n      b.is_copac_ramp,\n      COALESCE (\n          b.ramp_review,\n          b.ramp_close\n      ) AS ramp,\n      COALESCE (\n          b.ramps_review,\n          b.ramps_close\n      ) AS ramps,\n      COALESCE(\n          b.high_severity_ind_review,\n          b.high_severity_ind_close\n      ) AS high_severity_ind,\n      b.is_gt_sample,\n      b.source,\n      b.has_content_deleted\n\n  FROM co_qa_all_decisions_ramps b\n\n\n      WHERE ds='2018-03-30'\n          AND close_system='SRT'\n          -- excludes jobs from queues\n          -- without Community Ops Quality Audit Config\n          AND has_co_quality_config = true\n          -- excludes jobs with no quality job type\n          AND has_mapped_quality_job_type = true\n          AND partition_ds='weekly'\n          AND has_past_quality_job = false\n  ),\n\n  decisions_with_mode AS (\n      SELECT DISTINCT\n          a.has_content_deleted,\n          b.mode,\n          a.high_severity_ind,\n          a.coalesced_user_id,\n  a.report_type,\n  a.organization,\n  a.employee_type,\n  a.report_intensity,\n  a.action_severity,\n  a.market_reporting,\n  a.market_group,\n  a.person_type,\n  a.ramp,\n  a.ramps,\n  a.queue_group,\n  a.queue_fbid,\n  a.queue_name,\n  a.review_system,\n  a.vertical,\n  a.work_city,\n  a.sub_vertical,\n  a.sigma_policy,\n  a.content_id,\n  a.identifier,\n  a.srt_decision_id,\n  a.close_event_time,\n  a.srt_time_responded,\n  a.is_gt_sample,\n  a.source\n\n      FROM decisions a\n      LEFT JOIN co_qa_all_samples_ramps b\n      ON  a.identifier = b.identifier\n      AND COALESCE(\n          a.srt_decision_id,\n          a.close_event_time\n      ) = COALESCE(b.srt_decision_id, b.close_event_time)\n      AND b.ds BETWEEN '2018-03-24' AND '2018-03-30'\n      AND b.partition_ds = 'daily'\n\n  ),\n\n  perm_deleted_dequeued_jobs AS (\n      SELECT\n          COUNT(DISTINCT identifier) AS dequeued_count,\n          ramp,\n          ramps,\n          b.queue_name\n      FROM (\n          SELECT\n            a.quality_source_job_id,\n            a.job_id,\n            b.reason\n          FROM single_review_tool_main a\n          JOIN (\n              SELECT\n                  job_id,\n                  reason\n              FROM single_review_tool_main\n                WHERE event='job_close_success'\n                AND ds>='2018-03-24'\n                AND decision_data IS NULL\n                AND vertical_name = 'COMMUNITY_OPS'\n          ) b\n          ON a.job_id = b.job_id\n\n        WHERE\n            a.creation_source = 'co_ramp'\n            AND a.event= 'job_create_success'\n            AND a.ds>='2018-03-24'\n      ) a\n      JOIN decisions_with_mode b\n      ON a.quality_source_job_id = b.identifier\n\n      WHERE a.reason LIKE '%permanently deleted%'\n\n      GROUP BY\n        ramp,\n        ramps,\n        b.queue_name\n  ),\n\n  row_number_non_ramps_sampled_items AS (\n      -- list of jobs available to sample for RAMPS\n      SELECT\n          ROW_NUMBER() OVER (\n            PARTITION BY\n              ramps,\n              queue_name\n            ORDER BY\n              is_gt_sample DESC,\n              identifier\n          ) AS supplemental_ramp_row_id,\n          coalesced_user_id,\n  report_type,\n  organization,\n  employee_type,\n  report_intensity,\n  action_severity,\n  market_reporting,\n  market_group,\n  person_type,\n  ramp,\n  ramps,\n  queue_group,\n  queue_fbid,\n  queue_name,\n  review_system,\n  vertical,\n  work_city,\n  sub_vertical,\n  sigma_policy,\n  content_id,\n  identifier,\n  srt_decision_id,\n  close_event_time,\n  srt_time_responded,\n  is_gt_sample,\n  source\n      FROM decisions_with_mode a\n\n      -- gets previoulsy generated quality jobs\n      LEFT JOIN (\n          SELECT\n              id1,\n              id2\n          FROM inc_dim_srt_job_to_srt_quality_job:di a\n          WHERE ds = '2018-03-30'\n      ) b\n      ON b.id1 = a.identifier\n\n      WHERE mode IS NULL\n      -- exclude jobs with previously created quality jobs\n      -- useful to exclude multi interaction jobs already sampled in\n      -- previous weeks\n      AND id2 IS NULL\n      AND COALESCE(has_content_deleted,FALSE)=FALSE\n  ),\n\n  sampled_items_per_queue AS (\n      SELECT\n          a.ramp,\n          a.ramps,\n          a.queue_name,\n          a.presampled_count,\n          b.dequeued_count,\n          (a.presampled_count - COALESCE(b.dequeued_count,0)) AS sampled_count\n\n      FROM (\n          SELECT\n              ramp,\n              ramps,\n              queue_name,\n              COUNT(identifier) AS presampled_count\n          FROM decisions_with_mode\n          WHERE mode IN (\n              'copac_ramp',\n              'ramp_daily',\n              'supplemental_plus50_daily'\n          )\n          GROUP BY\n              ramp,\n              ramps,\n              queue_name\n      ) a\n\n      LEFT JOIN perm_deleted_dequeued_jobs b\n      ON a.ramps = b.ramps\n      AND a.queue_name = b.queue_name\n\n      GROUP BY\n          a.ramp,\n          a.ramps,\n          a.queue_name,\n          a.presampled_count,\n          b.dequeued_count\n  ),\n\n  supplemental_target AS (\n      -- calculates supplemental RAMPS sampling target\n      SELECT\n          a.ramp,\n          a.ramps,\n          a.queue_name,\n          a.target_per_queue,\n          b.sampled_count,\n          a.target_per_queue - COALESCE(b.sampled_count,0)\n          AS ramp_supplemental_target\n\n      FROM co_qa_target_per_queue_ramps a\n\n      LEFT JOIN sampled_items_per_queue b\n      ON a.ramps = b.ramps\n      AND a.queue_name = b.queue_name\n\n      WHERE a.ds = '2018-03-30'\n      AND a.partition_ds = 'weekly'\n      GROUP BY\n          a.ramp,\n          a.ramps,\n          a.queue_name,\n          a.target_per_queue,\n          b.sampled_count\n  ),\n\n  supplemental_ramp_weekly AS (\n      -- samples additionl jobs for ramp if necessary\n      SELECT\n          a.supplemental_ramp_row_id,\n          a.coalesced_user_id,\n  a.report_type,\n  a.organization,\n  a.employee_type,\n  a.report_intensity,\n  a.action_severity,\n  a.market_reporting,\n  a.market_group,\n  a.person_type,\n  a.ramp,\n  a.ramps,\n  a.queue_group,\n  a.queue_fbid,\n  a.queue_name,\n  a.review_system,\n  a.vertical,\n  a.work_city,\n  a.sub_vertical,\n  a.sigma_policy,\n  a.content_id,\n  a.identifier,\n  a.srt_decision_id,\n  a.close_event_time,\n  a.srt_time_responded,\n  a.is_gt_sample,\n  a.source\n      FROM row_number_non_ramps_sampled_items a\n      JOIN supplemental_target b\n      USING (\n          ramps,\n          ramp,\n          queue_name\n      )\n      WHERE a.supplemental_ramp_row_id <= b.ramp_supplemental_target\n  ),\n\n  ramp_plus_50_weekly_total AS (\n      -- aggregates supplemental ramps samples with already sampled items\n      SELECT\n          'supplemental_ramp_weekly' as mode,\n          coalesced_user_id,\n  report_type,\n  organization,\n  employee_type,\n  report_intensity,\n  action_severity,\n  market_reporting,\n  market_group,\n  person_type,\n  ramp,\n  ramps,\n  queue_group,\n  queue_fbid,\n  queue_name,\n  review_system,\n  vertical,\n  work_city,\n  sub_vertical,\n  sigma_policy,\n  content_id,\n  identifier,\n  srt_decision_id,\n  close_event_time,\n  srt_time_responded,\n  is_gt_sample,\n  source\n      FROM supplemental_ramp_weekly\n\n      UNION ALL\n\n      SELECT\n          mode,\n          coalesced_user_id,\n  report_type,\n  organization,\n  employee_type,\n  report_intensity,\n  action_severity,\n  market_reporting,\n  market_group,\n  person_type,\n  ramp,\n  ramps,\n  queue_group,\n  queue_fbid,\n  queue_name,\n  review_system,\n  vertical,\n  work_city,\n  sub_vertical,\n  sigma_policy,\n  content_id,\n  identifier,\n  srt_decision_id,\n  close_event_time,\n  srt_time_responded,\n  is_gt_sample,\n  source\n      FROM decisions_with_mode\n      WHERE mode IN (\n          'supplemental_plus50_daily',\n          'copac_ramp',\n          'ramp_daily'\n      )\n  ),\n\n  rep_sampled_count AS (\n      -- count of audit samples per rep for current week\n      SELECT\n          COUNT(DISTINCT identifier) AS rep_sampled,\n          coalesced_user_id\n      FROM ramp_plus_50_weekly_total\n      WHERE employee_type != 'Automation'\n      GROUP BY coalesced_user_id\n  ),\n\n  row_number_non_plus_50_sampled_items AS (\n      --list for decisions available to sample for plus 50\n      SELECT\n          a.mode,\n          a.coalesced_user_id,\n  a.report_type,\n  a.organization,\n  a.employee_type,\n  a.report_intensity,\n  a.action_severity,\n  a.market_reporting,\n  a.market_group,\n  a.person_type,\n  a.ramp,\n  a.ramps,\n  a.queue_group,\n  a.queue_fbid,\n  a.queue_name,\n  a.review_system,\n  a.vertical,\n  a.work_city,\n  a.sub_vertical,\n  a.sigma_policy,\n  a.content_id,\n  a.identifier,\n  a.srt_decision_id,\n  a.close_event_time,\n  a.srt_time_responded,\n  a.is_gt_sample,\n  a.source,\n          ROW_NUMBER() OVER (\n              PARTITION BY\n                  a.coalesced_user_id\n              ORDER BY\n                  a.is_gt_sample DESC,\n                  a.identifier\n          ) AS rep_row_id\n\n      FROM decisions_with_mode a\n\n      -- gets previoulsy generated quality jobs\n      LEFT JOIN (\n          SELECT\n              id1,\n              id2\n          FROM inc_dim_srt_job_to_srt_quality_job:di a\n          WHERE ds = '2018-03-30'\n      ) b\n      ON b.id1 = a.identifier\n\n      -- gets jobs sampled under 'supplemental_ramp_weekly'\n      LEFT JOIN (\n          SELECT DISTINCT\n              identifier\n          FROM ramp_plus_50_weekly_total\n      ) c\n\n      ON c.identifier = a.identifier\n\n      WHERE\n          a.mode IS NULL\n          -- exclude jobs with previously created quality jobs\n          -- useful to exclude multi interaction jobs already sampled\n          -- in previous weeks\n          AND b.id2 IS NULL\n          -- exclude jobs sampled under 'supplemental_ramp_weekly'\n          AND c.identifier IS NULL\n          AND a.employee_type != 'Automation'\n          AND COALESCE(a.has_content_deleted, FALSE) = FALSE\n  ),\n\n  supplemental_plus50_weekly AS (\n      -- samples additional plus 50 items if necessary\n      SELECT\n          a.rep_row_id,\n          a.coalesced_user_id,\n  a.report_type,\n  a.organization,\n  a.employee_type,\n  a.report_intensity,\n  a.action_severity,\n  a.market_reporting,\n  a.market_group,\n  a.person_type,\n  a.ramp,\n  a.ramps,\n  a.queue_group,\n  a.queue_fbid,\n  a.queue_name,\n  a.review_system,\n  a.vertical,\n  a.work_city,\n  a.sub_vertical,\n  a.sigma_policy,\n  a.content_id,\n  a.identifier,\n  a.srt_decision_id,\n  a.close_event_time,\n  a.srt_time_responded,\n  a.is_gt_sample,\n  a.source\n      FROM row_number_non_plus_50_sampled_items a\n      LEFT JOIN rep_sampled_count b\n          USING (coalesced_user_id)\n      WHERE\n          a.rep_row_id <= 53 - (COALESCE(b.rep_sampled,0))\n  )\n\n  -- gets all samples generated on ramp_plus_50_weekly_total\n  SELECT\n      mode,\n      coalesced_user_id,\n  report_type,\n  organization,\n  employee_type,\n  report_intensity,\n  action_severity,\n  market_reporting,\n  market_group,\n  person_type,\n  ramp,\n  ramps,\n  queue_group,\n  queue_fbid,\n  queue_name,\n  review_system,\n  vertical,\n  work_city,\n  sub_vertical,\n  sigma_policy,\n  content_id,\n  identifier,\n  srt_decision_id,\n  close_event_time,\n  srt_time_responded,\n  is_gt_sample,\n  source\n  FROM ramp_plus_50_weekly_total\n  WHERE mode IN (\n      'copac_ramp',\n      'supplemental_plus50_daily',\n      'supplemental_ramp_weekly',\n      'ramp_daily'\n  )\n\n  UNION ALL\n\n  -- gets all supplemental_plus50_weekly samples\n  SELECT\n      'supplemental_plus50_weekly' AS mode,\n      coalesced_user_id,\n  report_type,\n  organization,\n  employee_type,\n  report_intensity,\n  action_severity,\n  market_reporting,\n  market_group,\n  person_type,\n  ramp,\n  ramps,\n  queue_group,\n  queue_fbid,\n  queue_name,\n  review_system,\n  vertical,\n  work_city,\n  sub_vertical,\n  sigma_policy,\n  content_id,\n  identifier,\n  srt_decision_id,\n  close_event_time,\n  srt_time_responded,\n  is_gt_sample,\n  source\n  FROM supplemental_plus50_weekly\n)
ftw2_adhoc3	prism	ad_metrics	20180313_161540_51001_58zw2	argus:argus:512934	SELECT\n\tdate.ds,\n  avg_pct_10d,\n  0.68 AS goal,\n  (0.68 - avg_pct_10d)/0.68 AS goal_diff\nFROM (\n  SELECT\n  \tDATE(dateid) AS ds\n  FROM\n\t\tdim_date:operations\n  WHERE dateid BETWEEN '2017-10-01' AND '2018-06-30'\n  AND weekdayname NOT IN ('Saturday', 'Sunday')\n) date\nLEFT JOIN (\nSELECT ds,\n       AVG(dap_pct) OVER ( ORDER BY ds ASC ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) as avg_pct_10d\n       \nFROM \n\n(\nSELECT \n    case \n         when DAY_OF_WEEK(date(allsales.ds)) = 6 THEN DATE_ADD('day', -1, date(allsales.ds))\n         when DAY_OF_WEEK(date(allsales.ds)) = 7 THEN DATE_ADD('day', -2 , date(allsales.ds))\n         ELSE date(allsales.ds)\n    end as ds,\n    COUNT(DISTINCT crm.user_account_id) as active_user,\n    COUNT(DISTINCT allsales.user_account_id) as total_user,\n    COUNT(DISTINCT crm.user_account_id) * 1.0 / COUNT(DISTINCT allsales.user_account_id) AS "dap_pct"\nFROM (\n        SELECT DISTINCT\n            user_account_id,\n            ds,\n            ROLE\n        FROM smi_user_details\n  \t\t\tWHERE ds >= '2017-08-01'\n  \t\t\t\tAND ROLE IS NOT NULL\n    ) allsales\n    LEFT OUTER JOIN (\n        SELECT DISTINCT\n            ds,\n            user_account_id\n        FROM\n            smi_user_datelist\n        WHERE\n            ds >= '2017-08-01'\n            AND l1_status IN(1, 2, 3)\n            AND event_type = 'all visits'\n    ) crm\n    ON allsales.user_account_id = crm.user_account_id\n    AND allsales.ds = crm.ds\nGROUP BY\n    1\n)\nhaving ds >= date('2017-10-01')\n) dap\nUSING (ds)
ftw2_batch	prism_batch	ad_metrics	20180331_020420_11653_nxtq8	dataswarm@worker@ad_metrics.roas.roas_business_metrics.create_roas_eligible_pixels	/* Generated */\nINSERT INTO roas_eligible_pixels (\n  "advertiser_name",\n  "ultimate_parent_name",\n  "agency_name",\n  "pixel_or_app_id",\n  "conversion_type",\n  "account_id",\n  "advertiser_vertical",\n  "region",\n  "level_2",\n  "level_4",\n  "level_8",\n  "level_12",\n  "pixel_or_apps_using_value_optimization",\n  "overall_7_day_revenue_dollars",\n  "overall_14_day_revenue_dollars",\n  "overall_28_day_revenue_dollars",\n  "overall_56_day_revenue_dollars",\n  "value_opt_7_day_revenue",\n  "value_opt_14_day_revenue",\n  "value_opt_28_day_revenue",\n  "value_opt_56_day_revenue",\n  "non_value_opt_ocvr_7_day_revenue",\n  "non_value_opt_ocvr_14_day_revenue",\n  "non_value_opt_ocvr_28_day_revenue",\n  "non_value_opt_ocvr_56_day_revenue",\n  "non_value_opt_mai_revenue",\n  "non_value_opt_catalog_sales_revenue",\n  "source_app_ids",\n  "ds"\n)\nSELECT\n  "advertiser_name",\n  "ultimate_parent_name",\n  "agency_name",\n  "pixel_or_app_id",\n  "conversion_type",\n  "account_id",\n  "advertiser_vertical",\n  "region",\n  "level_2",\n  "level_4",\n  "level_8",\n  "level_12",\n  "pixel_or_apps_using_value_optimization",\n  "overall_7_day_revenue_dollars",\n  "overall_14_day_revenue_dollars",\n  "overall_28_day_revenue_dollars",\n  "overall_56_day_revenue_dollars",\n  "value_opt_7_day_revenue",\n  "value_opt_14_day_revenue",\n  "value_opt_28_day_revenue",\n  "value_opt_56_day_revenue",\n  "non_value_opt_ocvr_7_day_revenue",\n  "non_value_opt_ocvr_14_day_revenue",\n  "non_value_opt_ocvr_28_day_revenue",\n  "non_value_opt_ocvr_56_day_revenue",\n  "non_value_opt_mai_revenue",\n  "non_value_opt_catalog_sales_revenue",\n  "source_app_ids",\n  '2018-03-29' AS "ds"\nFROM (\n  /* User-provided */\n  SELECT\n      a.advertiser_name,\n      d.ultimate_parent_name,\n      d.agency_name,\n      a.target_id pixel_or_app_id,\n      case\n          when a.conversion_type = 'offsite_engagement' then 'Catalog_Sales'\n        when a.conversion_type = 'mobile_app_install' then 'App_Installs'\n        when a.conversion_type = 'offsite_conversion' then 'Offsite_Conversion'\n        else a.conversion_type\n      end conversion_type,\n      a.account_id,\n      a.advertiser_vertical,\n      a.region,\n      b.level_2,\n      b.level_4,\n      b.level_8,\n      b.level_12,\n      c.pixel_or_apps_using_value_optimization,\n      d.overall_7_day_revenue_dollars,\n      d.overall_14_day_revenue_dollars,\n      d.overall_28_day_revenue_dollars,\n      d.overall_56_day_revenue_dollars,\n      d.value_opt_7_day_revenue,\n      d.value_opt_14_day_revenue,\n      d.value_opt_28_day_revenue,\n      d.value_opt_56_day_revenue,\n      d.non_value_opt_ocvr_7_day_revenue,\n      d.non_value_opt_ocvr_14_day_revenue,\n      d.non_value_opt_ocvr_28_day_revenue,\n      d.non_value_opt_ocvr_56_day_revenue,\n      d.non_value_opt_MAI_revenue,\n      d.non_value_opt_catalog_sales_revenue,\n      d.source_app_ids\n  FROM\n      (select * from roas_eligible_for_bqrt_candidates:ad_delivery\n       where ds = '2018-03-29' and filter = 'train_100' and advertiser_name != 'UNKNOWN') a\n  left join\n      (SELECT\n              ad_account_id,\n              ad_account_name,\n              level_2,\n              level_4,\n              level_6,\n              level_8,\n              level_10,\n              level_12,\n              level_14\n          FROM\n              ad_account_territory_map:edw_bir01\n          WHERE\n              ds = '2018-03-29') b\n  on a.account_id = b.ad_account_id\n  left join\n      (select\n          account_id,\n          count(distinct target_id) pixel_or_apps_using_value_optimization\n       from roas_ads\n       where ds = '2018-03-29'\n       and optimization_goal = 22\n       group by 1) c\n  on\n      c.account_id = a.account_id\n  left join\n      (select\n          account_id,\n          ARRAY_AGG(DISTINCT source_app_id) source_app_ids,\n          arbitrary(ultimate_parent_name) ultimate_parent_name,\n          arbitrary(agency_name) agency_name,\n          arbitrary(brand_name) brand_name,\n          sum(legal_revenue_7_day)/100 overall_7_day_revenue_dollars,\n          sum(legal_revenue_14_day)/100 overall_14_day_revenue_dollars,\n          sum(legal_revenue_28_day)/100 overall_28_day_revenue_dollars,\n          sum(legal_revenue_56_day)/100 overall_56_day_revenue_dollars,\n          sum(case when optimization_goal = 22 then legal_revenue_7_day else 0 end)/100 value_opt_7_day_revenue,\n          sum(case when optimization_goal = 22 then legal_revenue_14_day else 0 end)/100 value_opt_14_day_revenue,\n          sum(case when optimization_goal = 22 then legal_revenue_28_day else 0 end)/100 value_opt_28_day_revenue,\n          sum(case when optimization_goal = 22 then legal_revenue_56_day else 0 end)/100 value_opt_56_day_revenue,\n          sum(case when optimization_goal = 8 then legal_revenue_7_day else 0 end)/100 non_value_opt_ocvr_7_day_revenue,\n          sum(case when optimization_goal = 8 then legal_revenue_14_day else 0 end)/100 non_value_opt_ocvr_14_day_revenue,\n          sum(case when optimization_goal = 8 then legal_revenue_28_day else 0 end)/100 non_value_opt_ocvr_28_day_revenue,\n          sum(case when optimization_goal = 8 then legal_revenue_56_day else 0 end)/100 non_value_opt_ocvr_56_day_revenue,\n          sum(case when (optimization_goal != 22 and objective in (17,37)) then legal_revenue_28_day else 0 end)/100 non_value_opt_MAI_revenue,\n          sum(case when objective = 29 then legal_revenue_28_day else 0 end)/100 non_value_opt_catalog_sales_revenue\n       from all_ads_details:bi\n       where ds = '2018-03-29'\n       and is_56_day_active = 1\n       group by 1) d\n  on d.account_id = a.account_id\n)
atn2_batch1	prism_batch	ad_delivery	20180314_232346_28142_nm5fj	dataswarm@test-lint@ad_delivery.bison.bison_simulation_vs_delivery_logs.populate_simulation_vs_delivery_logs_tasks[subpart_9]	SELECT\n          simulation.trace_id,\n          simulation.caller,\n          simulation.experiment_id,\n          simulation.campaign_id,\n          simulation.userid AS user_id,\n          simulation.page_type,\n          simulation.optimization_goal,\n          delivery.ecvr AS ecvr,\n          simulation.ecvr AS simulation_ecvr,\n          delivery.quality_value AS organic_bid,\n          simulation.organic_bid AS simulation_organic_bid\n        FROM (\n          SELECT\n            trace_id,\n            caller,\n            experiment_id,\n            campaign_id,\n            userid,\n            page_type,\n            optimization_goal,\n            ecvr_and_organic_bid_map['ecvr'] AS ecvr,\n            ecvr_and_organic_bid_map['organic_bid'] AS organic_bid\n          FROM (\n            SELECT\n              trace_id,\n              caller,\n              experiment_id,\n              campaign_id,\n              optimization_goal,\n              ecvr_and_organic_bid_by_user_page_type\n            FROM bison_backend_prediction_log\n            WHERE ds='2018-03-08'\n              AND mod(mod(from_big_endian_64(xxhash64(to_utf8(cast(campaign_id AS varchar)))), 13) + 13, 13) = 9\n              AND ecvr_and_organic_bid_by_user_page_type != MAP()\n          )\n          CROSS JOIN UNNEST(ecvr_and_organic_bid_by_user_page_type) AS t(userid, ecvr_and_organic_bid_by_page_type)\n          CROSS JOIN UNNEST(ecvr_and_organic_bid_by_page_type) AS t(page_type, ecvr_and_organic_bid_map)\n        ) simulation\n        INNER JOIN bison_delivery_log_aggregated_by_user_campaign delivery\n        USING (campaign_id, userid, page_type)\n        WHERE delivery.ds='2018-03-08'
carbon_batch	prism_batch	operations	20180401_015646_07370_di6ar	dataswarm@worker@operations.co_quality.r42_market_metrics_postman.load_data[LITHUANIAN]	WITH base_metrics AS (\n\n    SELECT\n        ds,\n        market_reporting ,\n        TRIM(queue_name) queue_name,\n        metric_name,\n        SUM(metric_value) metric_value\n    FROM\n        fct_job_summary_daily\n    WHERE\n        ds IN ('2018-03-29','2018-03-30')\n        AND market_reporting = 'LITHUANIAN'\n        AND known_bug = 0\n        AND metric_name IN (\n            'intr_ers_close_on_time_cnt',\n            'intr_ers_close_cnt',\n            'inventory_late_cnt',\n            'intr_ers_incoming_non_dupe_cnt'\n        )\n    GROUP BY 1,2,3,4\n),\n\ndaily_metrics_organized AS (\n\n    SELECT DISTINCT\n        a.ds,\n        a.market_reporting,\n        a.queue_name,\n        CASE WHEN b.metric_name = 'intr_ers_incoming_non_dupe_cnt' THEN b.metric_value END incoming_non_dupe_cnt,\n        CASE WHEN b.metric_name = 'intr_ers_close_cnt' THEN b.metric_value END closed,\n        CASE WHEN b.metric_name = 'intr_ers_close_on_time_cnt' THEN b.metric_value END closed_on_time,\n        CASE WHEN b.metric_name = 'intr_ers_close_cnt' THEN b.metric_value END -\n        CASE WHEN a.metric_name = 'intr_ers_close_on_time_cnt' THEN a.metric_value END closed_late,\n        CASE WHEN b.metric_name = 'inventory_late_cnt' THEN b.metric_value END late_inventory\n    FROM base_metrics a\n        JOIN base_metrics b\n        USING (ds, market_reporting , queue_name)\n    WHERE a.ds = '2018-03-30'\n),\n\ndod_variance AS (\n\n    SELECT DISTINCT\n        '2018-03-30' ds, a.market_reporting, a.queue_name,\n        CASE WHEN b.ds = '2018-03-30' THEN b.metric_value END /\n        CASE WHEN a.ds = '2018-03-29' THEN a.metric_value END -1 dod_variance_perc\n\n    FROM base_metrics a\n        JOIN base_metrics b\n        USING (market_reporting , queue_name, metric_name )\n    WHERE a.metric_name = 'intr_ers_incoming_non_dupe_cnt'\n)\n\nSELECT\n    a.market_reporting, a.queue_name,\n    COALESCE(MAX(closed),0) closed,\n    COALESCE(MAX(closed_on_time),0) closed_on_time,\n    COALESCE(MAX(closed_late),0) closed_late,\n    COALESCE(MAX(late_inventory),0) late_inventory,\n    COALESCE(MAX(incoming_non_dupe_cnt),0) incoming_non_dupe_cnt,\n    COALESCE(ROUND(MAX(b.dod_variance_perc) * 100,2),0) dod_variance_perc,\n    a.ds\nFROM daily_metrics_organized a\n    JOIN dod_variance b\n    USING (ds, market_reporting , queue_name)\n\nGROUP BY 1,2,9
atn2_batch1	prism_batch	ad_delivery	20180314_213246_24834_nm5fj	dataswarm@test-lint@ad_delivery.bison.bison_simulation_vs_delivery_logs.populate_simulation_vs_delivery_logs_tasks[subpart_2]	SELECT\n          simulation.trace_id,\n          simulation.caller,\n          simulation.experiment_id,\n          simulation.campaign_id,\n          simulation.userid AS user_id,\n          simulation.page_type,\n          simulation.optimization_goal,\n          delivery.ecvr AS ecvr,\n          simulation.ecvr AS simulation_ecvr,\n          delivery.organic_bid AS organic_bid,\n          simulation.organic_bid AS simulation_organic_bid\n        FROM (\n          SELECT\n            trace_id,\n            caller,\n            experiment_id,\n            campaign_id,\n            userid,\n            page_type,\n            optimization_goal,\n            ecvr_and_organic_bid_map['ecvr'] AS ecvr,\n            ecvr_and_organic_bid_map['organic_bid'] AS organic_bid\n          FROM (\n            SELECT\n              trace_id,\n              caller,\n              experiment_id,\n              campaign_id,\n              optimization_goal,\n              ecvr_and_organic_bid_by_user_page_type\n            FROM bison_backend_prediction_log\n            WHERE ds='2018-03-08'\n              AND mod(mod(from_big_endian_64(xxhash64(to_utf8(cast(campaign_id AS varchar)))), 13) + 13, 13) = 2\n              AND ecvr_and_organic_bid_by_user_page_type != MAP()\n          )\n          CROSS JOIN UNNEST(ecvr_and_organic_bid_by_user_page_type) AS t(userid, ecvr_and_organic_bid_by_page_type)\n          CROSS JOIN UNNEST(ecvr_and_organic_bid_by_page_type) AS t(page_type, ecvr_and_organic_bid_map)\n        ) simulation\n        INNER JOIN (\n          SELECT\n            campaign_id,\n            userid,\n            page_type,\n            ecvr,\n            quality_value AS organic_bid\n          FROM bison_delivery_log_aggregated_by_user_campaign\n          WHERE ds='2018-03-08'\n            AND mod(mod(from_big_endian_64(xxhash64(to_utf8(cast(campaign_id AS varchar)))), 13) + 13, 13) = 2\n        ) delivery\n        USING (campaign_id, userid, page_type)
atn3_batch4	prism_batch	infrastructure	20180317_075012_22273_qa22e	dataswarm@worker@infrastructure.oculus_metrics.oc_pacific_companionapp_danny_oleson.oc_pacific_companion_app_summary_danny_oleson	/* Generated */\nINSERT INTO oc_pacific_companion_app_summary_danny_oleson (\n  "task_number",\n  "activity_date",\n  "status",\n  "tags_match",\n  "ds"\n)\nSELECT\n  "task_number",\n  "activity_date",\n  "status",\n  "tags_match",\n  '2018-03-17' AS "ds"\nFROM (\n  /* User-provided */\n  -- ----------------------------------\n  -- CompanionApp\n  -- SUMMARY\n  -- ----------------------------------\n\n  /*\n      Note that most of this code is identical to that used in creating ai_qa_workload_changes_DannyOleson,\n      but the end result is different.\n      Here we are going to generate the entire table of tasks/dates/status/tags_matching.\n\n      Yes, optimization is possible.\n  */\n\n                   --\n                   -- =====================================================================\n                   -- Re-establish the metadata needed for this phase of analysis\n                   --\n  WITH get_partition (ds_our_tables)\n       AS            (SELECT MAX(ds) AS ds_our_tables\n                      FROM   oc_pacific_companion_app_params_danny_oleson\n                     )\n            --\n            --\n     , params     (  period, stop_varchar,  stop_date,  stop_unixtime, period_seconds, ds_source\n                   , burndown_start, target_burndown, burndown_eval_period_days\n                   , incl_tags1, NbrToIncl1, incl_match_crit1, incl_tags2, NbrToIncl2, incl_match_crit2\n                   , excl_tags1, NbrToExcl1, excl_match_crit1, excl_tags2, NbrToExcl2, excl_match_crit2\n                   , priorities_sought, time_range_4_priorities_set\n                   , tags_for_time_check, timed_tags_match_crit, time_range_4_tags_set)\n                   --\n       AS         (SELECT DISTINCT\n                          period\n                        , stop_varchar\n                        , CAST(stop_varchar AS DATE) AS stop_date\n                        , stop_unixtime\n                        , period_seconds\n                        , ds_source\n                     --\n                        , burndown_start\n                        , target_burndown\n                        , burndown_eval_period_days\n                     --\n                        , incl_tags1\n                        , NbrToIncl1\n                        , incl_match_crit1\n                     --\n                        , incl_tags2\n                        , NbrToIncl2\n                        , incl_match_crit2\n                     --\n                        , excl_tags1\n                        , NbrToExcl1\n                        , excl_match_crit1\n                     --\n                        , excl_tags2\n                        , NbrToExcl2\n                        , excl_match_crit2\n                     --\n                        , priorities_sought\n                        , time_range_4_priorities_set\n                     --\n                        , tags_for_time_check\n                        , timed_tags_match_crit\n                        , time_range_4_tags_set\n                     --\n                   FROM   oc_pacific_companion_app_params_danny_oleson\n                   WHERE  ds = (SELECT ds_our_tables FROM get_partition)\n                  )\n                   -- SELECT * FROM params /*\n                   -- -----------------------------------------------------------------------\n  -- PARAMS\n  -- oc_pacific_all_params_danny_oleson\n  -- oc_pacific_phase_mp_br_cut_oct06_params_danny_oleson\n  -- oc_pacific_phase_day0_feat_compl_params_danny_oleson\n  -- oc_pacific_phase_mp_gm_nov20_params_danny_oleson\n  -- oc_pacific_phase_day0_br_cut_dec04_params_danny_oleson\n  -- oc_pacific_phase_day0_gm_Jan24_params_danny_oleson\n  -- worlds_bugs_params_juliet_talcott\n  -- worlds_sprint_params_juliet_talcott\n  -- monterey_funpak_triage_and_bugs_params_juliet_talcott\n  -- oc_twilight_params_danny_oleson\n  -- oc_sculpt_bug_params__danny_oleson\n  -- oc_sculpt_v1_3_params__danny_oleson\n  -- oc_dash_and_dash_launch_high_params__danny_oleson\n  -- oc_worlds_and_launch_high_params__danny_oleson\n  -- oc_pacific_mp_milestones_params__danny_oleson\n  -- oc_pacific_day0_milestones_params__danny_oleson\n  --\n  --\n                   -- -----------------------------------------------------------------------                  --\n                    -- Re-establish the care data needed for this phase of analysis\n                    --\n    , core3           (rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match)\n      AS              (SELECT DISTINCT\n                              ROW_NUMBER() OVER (PARTITION BY task_number ORDER BY task_number, task_activity_time) AS rowno\n                            , task_number\n                            , task_created_time\n                            , task_completed_time\n                            , status\n                            , task_activity_time\n                            , tags_match\n                       FROM   oc_pacific_companion_app_core2_danny_oleson\n                       WHERE  ds = (SELECT ds_our_tables FROM get_partition)\n                      )  --\n                   -- -----------------------------------------------------------------------\n  -- CORE2\n  -- oc_pacific_all_core2_danny_oleson\n  -- oc_pacific_phase_mp_br_cut_oct06_core2_danny_oleson\n  -- oc_pacific_phase_day0_feat_compl_core2_danny_oleson\n  -- oc_pacific_phase_mp_gm_nov20_core2_danny_oleson\n  -- oc_pacific_phase_day0_br_cut_dec04_core2_danny_oleson\n  -- oc_pacific_phase_day0_gm_Jan24_core2_danny_oleson\n  -- worlds_bugs_core2_juliet_talcott\n  -- worlds_sprint_core2_juliet_talcott\n  -- monterey_funpak_triage_and_bugs_core2_juliet_talcott\n  -- oc_twilight_core2_danny_oleson\n  -- oc_sculpt_bug_core2__danny_oleson\n  -- oc_sculpt_v1_3_core2__danny_oleson\n  -- oc_dash_and_dash_launch_high_core2__danny_oleson\n  -- oc_worlds_and_launch_high_core2__danny_oleson\n  -- oc_pacific_mp_milestones_core2__danny_oleson\n  -- oc_pacific_day0_milestones_core2__danny_oleson\n  --\n  --\n    , first_row      (rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match)\n      AS             (SELECT rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match\n                      FROM core3\n                      WHERE rowno = 1\n                     )\n                   --\n                   --\n    , date_extremes  (task_number, first_date, last_date)\n      AS             (SELECT DISTINCT\n                             task_number\n                           , MIN(task_activity_time)  AS first_date\n                           , MAX(task_activity_time)  AS last_date\n                      FROM   first_row\n                      GROUP BY 1\n                     ) -- select * from date_extremes /*\n                   --\n                   --\n                   -- -----------------------------------------------------------------------\n\n                   --\n                   -- Collect just the rows of interest\n                   -- Meaning, only keep when there is a change of relevance, do not need rows that do not denote any change of relevance\n                   -- Skipping identicals, keeping only the lower row.\n                   --\n    , row_rollup     (rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match)\n      AS             (SELECT b.rowno, b.task_number, b.task_created_time, b.task_completed_time, b.status, b.task_activity_time, b.tags_match\n                      FROM   core3 a\n                      JOIN   core3 b\n                        ON   b.rowno = a.rowno + 1\n                       AND   a.task_number = b.task_number\n                       AND  (a.status     !=  b.status\n                        OR   a.tags_match !=  b.tags_match)\n                      ORDER BY a.task_number, a.task_activity_time\n                     )\n                   --  select date(from_unixtime(task_activity_time)) as activity_date, * from row_rollup\n                   --\n                   --\n                   -- -----------------------------------------------------------------------\n                   --\n                   -- This is the core of what we need, the first entry, and all lower rows that change from their above row\n                   --\n    , all_changes    (task_number, task_activity_time, status, tags_match)\n      AS             (SELECT task_number, task_activity_time, status, tags_match FROM first_row\n                      UNION\n                      SELECT task_number, task_activity_time, status, tags_match FROM row_rollup\n                     ) -- select * from all_changes /*\n                   --\n                   --\n                   --\n                   --\n                   -- But for the top comment, all the above is identical to the code in Summary\n                   -- =======================================================================\n                   --\n                   --\n                   --\n                   -- If the last row for a task has status 'OPEN', generate a new end date\n                   -- aka, generate OPEN status rows on stop_unixtime when last data row is OPEN\n                   --\n    , get_end        (task_number, task_activity_time, status, tags_match)\n      AS             (SELECT ac.task_number\n                           , (SELECT stop_unixtime FROM params) AS task_activity_time\n                           , status\n                           , tags_match\n                      FROM   all_changes       ac\n                      WHERE  status     = 'OPEN'\n                        AND  tags_match = 'YES'\n                        AND  task_activity_time = (SELECT MAX(task_activity_time) FROM all_changes ac2 WHERE ac.task_number = ac2.task_number)\n                     ) -- select * from get_end /*\n                   --\n                   -- Combine all data (all_changes) with any newly extended ending date for OPEN tasks\n                   --\n    , all_rows       (task_number, task_activity_time, status, tags_match)\n      AS             (SELECT task_number\n                           , task_activity_time\n                           , status\n                           , tags_match\n                      FROM   all_changes\n                      UNION  (SELECT * FROM get_end)\n                     ) -- select DATE(FROM_UNIXTIME(task_activity_time)) AS activity_date, * from all_rows /*\n                   --\n                   -- Need a row number and a true date field to proceed\n                   --\n    , build_prep     (rowno, task_number, activity_date, status, tags_match)\n      AS             (SELECT ROW_NUMBER() OVER (PARTITION BY task_number ORDER BY task_number, task_activity_time) AS rowno\n                           , task_number\n                           , DATE(FROM_UNIXTIME(task_activity_time)) AS activity_date\n                           , status\n                           , tags_match\n                      FROM   all_rows\n                      ORDER BY task_number, task_activity_time\n                     )\n                   --\n                   -- Using data from two rows, two times, fill the spans in between with preceeding data\n                   -- All but the very last row gets consumed.\n                   -- (Cannot get 1st AND last in a span w/o duplicates when moving to the next span.)\n                   --\n    , summary_less_last (task_number, activity_date, status, tags_match)\n      AS                (SELECT task_number\n                              , CAST(DATE_ADD('DAY', id-1, start_on) AS VARCHAR) AS activity_date\n                              , status\n                              , tags_match\n                         FROM\n                             (SELECT bp1.task_number\n                                   , bp1.status\n                                   , bp1.tags_match\n                                   , bp1.activity_date AS start_on\n                                   , bp2.activity_date AS stop_before\n                              FROM   build_prep bp1\n                              JOIN   build_prep bp2\n                                ON   bp2.rowno = bp1.rowno + 1\n                               AND   bp1.task_number = bp2.task_number\n                             ) a\n                             ,\n                             t5000 t\n                         WHERE  DATE_ADD('DAY', id, start_on) <= stop_before\n                        ) -- select * from summary_less_last /*\n                   --\n                   -- Like we did above, get the very last row of data for each task\n                   --\n    , last_row       (task_number, activity_date, status, tags_match)\n      AS             (SELECT bp.task_number\n                           , CAST(bp.activity_date AS VARCHAR)\n                           , status\n                           , tags_match\n                      FROM   build_prep bp\n                      JOIN  (SELECT   task_number\n                                  ,   MAX(rowno) as last_row\n                             FROM     build_prep\n                             GROUP BY task_number\n                            ) a\n                        ON   bp.task_number = a.task_number\n                       AND   bp.rowno = a.last_row\n                     )\n                   --\n                   --\n                   -- And as we did before, appened the data to get all data for all dates\n                   --\n    , summary        (task_number, activity_date, status, tags_match)\n      AS             (SELECT * FROM summary_less_last\n                      UNION ALL\n                      SELECT * FROM last_row\n                     )\n  --\n  -- RESULTS IN TABLE:  oc_pacific_companion_app_summary_danny_oleson\n  --\n  SELECT * FROM summary ORDER BY task_number, activity_date\n\n  -- -----------------------------------------------------------------------\n  -- SUMMARY\n  -- oc_pacific_all_summary_danny_oleson\n  -- oc_pacific_phase_mp_br_cut_oct06_summary_danny_oleson\n  -- oc_pacific_phase_day0_feat_compl_summary_danny_oleson\n  -- oc_pacific_phase_mp_gm_nov20_summary_danny_oleson\n  -- oc_pacific_phase_day0_br_cut_dec04_summary_danny_oleson\n  -- oc_pacific_phase_day0_gm_Jan24_summary_danny_oleson\n  -- worlds_bugs_summary_juliet_talcott\n  -- worlds_sprint_summary_juliet_talcott\n  -- monterey_funpak_triage_and_bugs_summary_juliet_talcott\n  -- oc_twilight_summary_danny_oleson\n  -- oc_sculpt_bug_summary__danny_oleson\n  -- oc_sculpt_v1_3_summary__danny_oleson\n  -- oc_dash_and_dash_launch_high_summary__danny_oleson\n  -- oc_worlds_and_launch_high_summary__danny_oleson\n  -- oc_pacific_mp_milestones_summary__danny_oleson\n  -- oc_pacific_day0_milestones_summary__danny_oleson\n  --\n  -- -----------------------------------------------------------------------\n)
atn3_batch3	prism_batch	infrastructure	20180321_164249_39643_evdnw	dataswarm@worker@infrastructure.oculus_metrics.oc_pacific_mobile_store_danny_oleson.oc_pacific_mobile_store_summary_danny_oleson	/* Generated */\nINSERT INTO oc_pacific_mobile_store_summary_danny_oleson (\n  "task_number",\n  "activity_date",\n  "status",\n  "tags_match",\n  "ds"\n)\nSELECT\n  "task_number",\n  "activity_date",\n  "status",\n  "tags_match",\n  '2018-03-21' AS "ds"\nFROM (\n  /* User-provided */\n  -- ----------------------------------\n  -- MobileStore\n  -- SUMMARY\n  -- ----------------------------------\n\n  /*\n      Note that most of this code is identical to that used in creating ai_qa_workload_changes_DannyOleson,\n      but the end result is different.\n      Here we are going to generate the entire table of tasks/dates/status/tags_matching.\n\n      Yes, optimization is possible.\n  */\n\n                   --\n                   -- =====================================================================\n                   -- Re-establish the metadata needed for this phase of analysis\n                   --\n  WITH get_partition (ds_our_tables)\n       AS            (SELECT MAX(ds) AS ds_our_tables\n                      FROM   oc_pacific_mobile_store_params_danny_oleson\n                     )\n            --\n            --\n     , params     (  period, stop_varchar,  stop_date,  stop_unixtime, period_seconds, ds_source\n                   , burndown_start, target_burndown, burndown_eval_period_days\n                   , incl_tags1, NbrToIncl1, incl_match_crit1, incl_tags2, NbrToIncl2, incl_match_crit2\n                   , excl_tags1, NbrToExcl1, excl_match_crit1, excl_tags2, NbrToExcl2, excl_match_crit2\n                   , priorities_sought, time_range_4_priorities_set\n                   , tags_for_time_check, timed_tags_match_crit, time_range_4_tags_set)\n                   --\n       AS         (SELECT DISTINCT\n                          period\n                        , stop_varchar\n                        , CAST(stop_varchar AS DATE) AS stop_date\n                        , stop_unixtime\n                        , period_seconds\n                        , ds_source\n                     --\n                        , burndown_start\n                        , target_burndown\n                        , burndown_eval_period_days\n                     --\n                        , incl_tags1\n                        , NbrToIncl1\n                        , incl_match_crit1\n                     --\n                        , incl_tags2\n                        , NbrToIncl2\n                        , incl_match_crit2\n                     --\n                        , excl_tags1\n                        , NbrToExcl1\n                        , excl_match_crit1\n                     --\n                        , excl_tags2\n                        , NbrToExcl2\n                        , excl_match_crit2\n                     --\n                        , priorities_sought\n                        , time_range_4_priorities_set\n                     --\n                        , tags_for_time_check\n                        , timed_tags_match_crit\n                        , time_range_4_tags_set\n                     --\n                   FROM   oc_pacific_mobile_store_params_danny_oleson\n                   WHERE  ds = (SELECT ds_our_tables FROM get_partition)\n                  )\n                   -- SELECT * FROM params /*\n                   -- -----------------------------------------------------------------------\n  -- PARAMS\n  -- oc_pacific_all_params_danny_oleson\n  -- oc_pacific_phase_mp_br_cut_oct06_params_danny_oleson\n  -- oc_pacific_phase_day0_feat_compl_params_danny_oleson\n  -- oc_pacific_phase_mp_gm_nov20_params_danny_oleson\n  -- oc_pacific_phase_day0_br_cut_dec04_params_danny_oleson\n  -- oc_pacific_phase_day0_gm_Jan24_params_danny_oleson\n  -- worlds_bugs_params_juliet_talcott\n  -- worlds_sprint_params_juliet_talcott\n  -- monterey_funpak_triage_and_bugs_params_juliet_talcott\n  -- oc_twilight_params_danny_oleson\n  -- oc_sculpt_bug_params__danny_oleson\n  -- oc_sculpt_v1_3_params__danny_oleson\n  -- oc_dash_and_dash_launch_high_params__danny_oleson\n  -- oc_worlds_and_launch_high_params__danny_oleson\n  -- oc_pacific_mp_milestones_params__danny_oleson\n  -- oc_pacific_day0_milestones_params__danny_oleson\n  --\n  --\n                   -- -----------------------------------------------------------------------                  --\n                    -- Re-establish the care data needed for this phase of analysis\n                    --\n    , core3           (rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match)\n      AS              (SELECT DISTINCT\n                              ROW_NUMBER() OVER (PARTITION BY task_number ORDER BY task_number, task_activity_time) AS rowno\n                            , task_number\n                            , task_created_time\n                            , task_completed_time\n                            , status\n                            , task_activity_time\n                            , tags_match\n                       FROM   oc_pacific_mobile_store_core2_danny_oleson\n                       WHERE  ds = (SELECT ds_our_tables FROM get_partition)\n                      )  --\n                   -- -----------------------------------------------------------------------\n  -- CORE2\n  -- oc_pacific_all_core2_danny_oleson\n  -- oc_pacific_phase_mp_br_cut_oct06_core2_danny_oleson\n  -- oc_pacific_phase_day0_feat_compl_core2_danny_oleson\n  -- oc_pacific_phase_mp_gm_nov20_core2_danny_oleson\n  -- oc_pacific_phase_day0_br_cut_dec04_core2_danny_oleson\n  -- oc_pacific_phase_day0_gm_Jan24_core2_danny_oleson\n  -- worlds_bugs_core2_juliet_talcott\n  -- worlds_sprint_core2_juliet_talcott\n  -- monterey_funpak_triage_and_bugs_core2_juliet_talcott\n  -- oc_twilight_core2_danny_oleson\n  -- oc_sculpt_bug_core2__danny_oleson\n  -- oc_sculpt_v1_3_core2__danny_oleson\n  -- oc_dash_and_dash_launch_high_core2__danny_oleson\n  -- oc_worlds_and_launch_high_core2__danny_oleson\n  -- oc_pacific_mp_milestones_core2__danny_oleson\n  -- oc_pacific_day0_milestones_core2__danny_oleson\n  --\n  --\n    , first_row      (rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match)\n      AS             (SELECT rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match\n                      FROM core3\n                      WHERE rowno = 1\n                     )\n                   --\n                   --\n    , date_extremes  (task_number, first_date, last_date)\n      AS             (SELECT DISTINCT\n                             task_number\n                           , MIN(task_activity_time)  AS first_date\n                           , MAX(task_activity_time)  AS last_date\n                      FROM   first_row\n                      GROUP BY 1\n                     ) -- select * from date_extremes /*\n                   --\n                   --\n                   -- -----------------------------------------------------------------------\n\n                   --\n                   -- Collect just the rows of interest\n                   -- Meaning, only keep when there is a change of relevance, do not need rows that do not denote any change of relevance\n                   -- Skipping identicals, keeping only the lower row.\n                   --\n    , row_rollup     (rowno, task_number, task_created_time, task_completed_time, status, task_activity_time, tags_match)\n      AS             (SELECT b.rowno, b.task_number, b.task_created_time, b.task_completed_time, b.status, b.task_activity_time, b.tags_match\n                      FROM   core3 a\n                      JOIN   core3 b\n                        ON   b.rowno = a.rowno + 1\n                       AND   a.task_number = b.task_number\n                       AND  (a.status     !=  b.status\n                        OR   a.tags_match !=  b.tags_match)\n                      ORDER BY a.task_number, a.task_activity_time\n                     )\n                   --  select date(from_unixtime(task_activity_time)) as activity_date, * from row_rollup\n                   --\n                   --\n                   -- -----------------------------------------------------------------------\n                   --\n                   -- This is the core of what we need, the first entry, and all lower rows that change from their above row\n                   --\n    , all_changes    (task_number, task_activity_time, status, tags_match)\n      AS             (SELECT task_number, task_activity_time, status, tags_match FROM first_row\n                      UNION\n                      SELECT task_number, task_activity_time, status, tags_match FROM row_rollup\n                     ) -- select * from all_changes /*\n                   --\n                   --\n                   --\n                   --\n                   -- But for the top comment, all the above is identical to the code in Summary\n                   -- =======================================================================\n                   --\n                   --\n                   --\n                   -- If the last row for a task has status 'OPEN', generate a new end date\n                   -- aka, generate OPEN status rows on stop_unixtime when last data row is OPEN\n                   --\n    , get_end        (task_number, task_activity_time, status, tags_match)\n      AS             (SELECT ac.task_number\n                           , (SELECT stop_unixtime FROM params) AS task_activity_time\n                           , status\n                           , tags_match\n                      FROM   all_changes       ac\n                      WHERE  status     = 'OPEN'\n                        AND  tags_match = 'YES'\n                        AND  task_activity_time = (SELECT MAX(task_activity_time) FROM all_changes ac2 WHERE ac.task_number = ac2.task_number)\n                     ) -- select * from get_end /*\n                   --\n                   -- Combine all data (all_changes) with any newly extended ending date for OPEN tasks\n                   --\n    , all_rows       (task_number, task_activity_time, status, tags_match)\n      AS             (SELECT task_number\n                           , task_activity_time\n                           , status\n                           , tags_match\n                      FROM   all_changes\n                      UNION  (SELECT * FROM get_end)\n                     ) -- select DATE(FROM_UNIXTIME(task_activity_time)) AS activity_date, * from all_rows /*\n                   --\n                   -- Need a row number and a true date field to proceed\n                   --\n    , build_prep     (rowno, task_number, activity_date, status, tags_match)\n      AS             (SELECT ROW_NUMBER() OVER (PARTITION BY task_number ORDER BY task_number, task_activity_time) AS rowno\n                           , task_number\n                           , DATE(FROM_UNIXTIME(task_activity_time)) AS activity_date\n                           , status\n                           , tags_match\n                      FROM   all_rows\n                      ORDER BY task_number, task_activity_time\n                     )\n                   --\n                   -- Using data from two rows, two times, fill the spans in between with preceeding data\n                   -- All but the very last row gets consumed.\n                   -- (Cannot get 1st AND last in a span w/o duplicates when moving to the next span.)\n                   --\n    , summary_less_last (task_number, activity_date, status, tags_match)\n      AS                (SELECT task_number\n                              , CAST(DATE_ADD('DAY', id-1, start_on) AS VARCHAR) AS activity_date\n                              , status\n                              , tags_match\n                         FROM\n                             (SELECT bp1.task_number\n                                   , bp1.status\n                                   , bp1.tags_match\n                                   , bp1.activity_date AS start_on\n                                   , bp2.activity_date AS stop_before\n                              FROM   build_prep bp1\n                              JOIN   build_prep bp2\n                                ON   bp2.rowno = bp1.rowno + 1\n                               AND   bp1.task_number = bp2.task_number\n                             ) a\n                             ,\n                             t5000 t\n                         WHERE  DATE_ADD('DAY', id, start_on) <= stop_before\n                        ) -- select * from summary_less_last /*\n                   --\n                   -- Like we did above, get the very last row of data for each task\n                   --\n    , last_row       (task_number, activity_date, status, tags_match)\n      AS             (SELECT bp.task_number\n                           , CAST(bp.activity_date AS VARCHAR)\n                           , status\n                           , tags_match\n                      FROM   build_prep bp\n                      JOIN  (SELECT   task_number\n                                  ,   MAX(rowno) as last_row\n                             FROM     build_prep\n                             GROUP BY task_number\n                            ) a\n                        ON   bp.task_number = a.task_number\n                       AND   bp.rowno = a.last_row\n                     )\n                   --\n                   --\n                   -- And as we did before, appened the data to get all data for all dates\n                   --\n    , summary        (task_number, activity_date, status, tags_match)\n      AS             (SELECT * FROM summary_less_last\n                      UNION ALL\n                      SELECT * FROM last_row\n                     )\n  --\n  -- RESULTS IN TABLE:  oc_pacific_mobile_store_summary_danny_oleson\n  --\n  SELECT * FROM summary ORDER BY task_number, activity_date\n\n  -- -----------------------------------------------------------------------\n  -- SUMMARY\n  -- oc_pacific_all_summary_danny_oleson\n  -- oc_pacific_phase_mp_br_cut_oct06_summary_danny_oleson\n  -- oc_pacific_phase_day0_feat_compl_summary_danny_oleson\n  -- oc_pacific_phase_mp_gm_nov20_summary_danny_oleson\n  -- oc_pacific_phase_day0_br_cut_dec04_summary_danny_oleson\n  -- oc_pacific_phase_day0_gm_Jan24_summary_danny_oleson\n  -- worlds_bugs_summary_juliet_talcott\n  -- worlds_sprint_summary_juliet_talcott\n  -- monterey_funpak_triage_and_bugs_summary_juliet_talcott\n  -- oc_twilight_summary_danny_oleson\n  -- oc_sculpt_bug_summary__danny_oleson\n  -- oc_sculpt_v1_3_summary__danny_oleson\n  -- oc_dash_and_dash_launch_high_summary__danny_oleson\n  -- oc_worlds_and_launch_high_summary__danny_oleson\n  -- oc_pacific_mp_milestones_summary__danny_oleson\n  -- oc_pacific_day0_milestones_summary__danny_oleson\n  --\n  -- -----------------------------------------------------------------------\n  /*\n  */\n)
de4ftw2	raptor	de	20180330_171218_05086_35b59	unidash:2056592444616686:argus:491950	/*\naggregate_type for cube:\n    - interface                  1\n    - country                    2\n    - region                     4\n    - locale                     8\n    - usecase_type              16\n    - filter_type               32\n    - video_state_type          64\n    - is_show_episode          128\n    \ncube has only next grouping sets:\n0, 6, 7, 22, 23, 38, 39, 70, 71, 87, 134, 135, 167, 255\n\nthus for missing we will be using closest one's\nthat impact searchers and sessions metrics quality\nas they are non-additive\n\n*/\n\nWITH agg_type_raw AS (\n\tSELECT\n  \t(0\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'interface', 1, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'country', 2, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'region', 4, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'locale', 8, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'usecase_type', 16, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'filter_type', 32, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'video_state_type', 64, 0)\n       + IF(CARDINALITY(ARRAY_EXCEPT(ARRAY['__ALL__'], ARRAY['__ALL__'])) > 0\n            OR 'ds' = 'is_show_episode', 128, 0)\n    ) AS aggregate_type\n),\nagg_type_adj AS (\n    SELECT\n        ARRAY_MIN(\n            FILTER(ARRAY [0, 6, 7, 22, 23, 38, 39, 70, 71, 87, 134, 135, 167, 255], \n                   x -> BITWISE_AND(aggregate_type, x) = aggregate_type)\n        ) AS aggregate_type\n    FROM agg_type_raw\n),\npre_agg AS (\n    SELECT\n        ds,\n        CASE\n  \t\t\t    WHEN 'ds' = 'ds'\n  \t\t\t\t\t\tTHEN ''\n  \t\t\t\t\tWHEN contains(aggregation_level, 'ds')\n  \t\t\t    \tTHEN COALESCE(CAST(ds AS VARCHAR), 'NULL')\n  \t\t\t    ELSE 'Overall'\n  \t\t\tEND AS dim,\n  \t\t\t/*---Watch Time---*/\n        (COALESCE(SUM(serp_video_watch_time_spent), 0) + \n  \t\t\t COALESCE(SUM(downstream_video_watch_time_spent), 0)\n        ) * 1.0 / 60 AS "SEARCH_WT",\n  \t\t\tSUM(serp_video_watch_time_spent) * 1.0 / 60 AS "SERP_WT",\n  \t\t\tSUM(downstream_video_watch_time_spent) * 1.0 / 60 AS "DS_WT",\n  \t\t\t/*---Volume---*/\n  \t\t\tSUM(sessions) AS "SEARCH_VOL_RAW",\n  \t\t\tSUM(sessions_w_serp_watch) AS "SERP_VOL_RAW",\n        SUM(sessions_w_true_watch) AS "SEARCH_VOL",\n  \t\t\tSUM(sessions_w_serp_true_watch) AS "SERP_VOL",\n        SUM(sessions_w_ds_true_watch) AS "DS_VOL",\n  \t\t\t/*---DAS---*/\n  \t\t\tSUM(searchers) AS "SEARCH_DAS_RAW",\n  \t\t\tSUM(searchers_w_serp_watch) AS "SERP_DAS_RAW",\n  \t\t\tSUM(searchers_w_true_watch) AS "SEARCH_DAS",\n  \t\t\tSUM(searchers_w_serp_true_watch) AS "SERP_DAS",\n  \t\t\tSUM(searchers_w_ds_true_watch) AS "DS_DAS"\n    FROM search_video_cube c\n    INNER JOIN agg_type_adj a USING (aggregate_type)\n    WHERE ds >= (DATE '2017-07-01')\n        AND (COALESCE(interface, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n        AND (COALESCE(country, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n        AND (COALESCE(region, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n\t\t\t  AND (COALESCE(locale, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n        AND (COALESCE(usecase_type, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n        AND (COALESCE(filter_type, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n        AND (COALESCE(video_state_type, 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n        AND (COALESCE(CAST(is_show_episode AS VARCHAR), 'NULL') IN ('__ALL__') \n            OR '__ALL__' IN ('__ALL__'))\n    GROUP BY ds,\n        CASE\n  \t\t\t    WHEN 'ds' = 'ds'\n  \t\t\t\t\t\tTHEN ''\n  \t\t\t\t\tWHEN contains(aggregation_level, 'ds')\n  \t\t\t    \tTHEN COALESCE(CAST(ds AS VARCHAR), 'NULL')\n  \t\t\t    ELSE 'Overall'\n  \t\t\tEND\n)\nSELECT \n    ds,\n    dim,\n    \n      AVG("SEARCH_VOL") OVER (PARTITION BY dim ORDER BY ds ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS "SEARCH_VOL-7d"\n\t\t\t\n      ,\n    \n      AVG("SERP_VOL") OVER (PARTITION BY dim ORDER BY ds ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS "SERP_VOL-7d"\n\t\t\t\n      ,\n    \n      AVG("DS_VOL") OVER (PARTITION BY dim ORDER BY ds ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS "DS_VOL-7d"\n\t\t\t\n      \n    \nFROM pre_agg\nORDER BY 1 DESC, 3 DESC
carbon	prism	aloha	20180315_132241_98465_dns5m	argus:argus:513494	SELECT ds,\nCOUNT(DISTINCT call_client_session_id) AS calls_initiated,\ndevice_serial_number,\nCOUNT(DISTINCT conference_name) AS conference_name_count,\nCOUNT(DISTINCT USER_INITIATED_CALL) AS USER_INITIATED_CALL,\nCOUNT(DISTINCT INCALL_UI_ATTACHED_CREATOR) AS INCALL_UI_ATTACHED_CREATOR,\nCOUNT(DISTINCT RTC_USING_CACHED_CONF_NAME) AS RTC_USING_CACHED_CONF_NAME,\nCOUNT(DISTINCT RTC_NOT_USING_CACHED_CONF_NAME) AS RTC_NOT_USING_CACHED_CONF_NAME,\nCOUNT(DISTINCT CONFERENCE_NAME_REQUEST) AS CONFERENCE_NAME_REQUEST,\nCOUNT(DISTINCT CONFERENCE_NAME_RESPONSE) AS CONFERENCE_NAME_RESPONSE,\nCOUNT(DISTINCT CREATE_RTC_CALL_CREATOR) AS CREATE_RTC_CALL_CREATOR,\nCOUNT(DISTINCT CREATE_RTC_CALL_SUCCESS_CREATOR) AS CREATE_RTC_CALL_SUCCESS_CREATOR,\nCOUNT(DISTINCT RTC_CALL_JOINED_CREATOR) AS RTC_CALL_JOINED_CREATOR,\nCOUNT(DISTINCT INVITE_PARTICIPANT_REQUEST) AS INVITE_PARTICIPANT_REQUEST,\nCOUNT(DISTINCT INVITE_PARTICIPANT_RESPONSE) AS INVITE_PARTICIPANT_RESPONSE,\nCOUNT(DISTINCT INVITE_PARTICIPANT_FAILED) AS INVITE_PARTICIPANT_FAILED,\nCOUNT(DISTINCT REMOTE_PARTICIPANT_CONNECTED) AS REMOTE_PARTICIPANT_CONNECTED,\nCOUNT(DISTINCT RTC_CALL_ENDED) AS RTC_CALL_ENDED,\nCOUNT(DISTINCT USER_HANG_UP_CALL) AS USER_HANG_UP_CALL,\nCOUNT(DISTINCT RTC_CALL_ENDED_CREATOR) AS RTC_CALL_ENDED_CREATOR,\nCOUNT(DISTINCT REMOTE_PARTICIPANT_DISCONNECTED) AS REMOTE_PARTICIPANT_DISCONNECTED,\nCOUNT(DISTINCT OMNISTORE_ACTIVE_CALL_REMOVE) AS OMNISTORE_ACTIVE_CALL_REMOVE,\nCOUNT(DISTINCT OMNISTORE_CALL_REJECTED) AS OMNISTORE_CALL_REJECTED,\nCOUNT(DISTINCT OMNISTORE_ACTIVE_CALL_ADD) AS OMNISTORE_ACTIVE_CALL_ADD,\nCOUNT(DISTINCT INCALL_UI_ATTACHED_PARTICIPANT) AS INCALL_UI_ATTACHED_PARTICIPANT,\nCOUNT(DISTINCT CREATE_RTC_CALL_PARTICIPANT) AS CREATE_RTC_CALL_PARTICIPANT,\nCOUNT(DISTINCT CREATE_RTC_CALL_SUCCESS_PARTICIPANT) AS CREATE_RTC_CALL_SUCCESS_PARTICIPANT,\nCOUNT(DISTINCT JOINING_CALL_PARTICIPANT) AS JOINING_CALL_PARTICIPANT,\nCOUNT(DISTINCT RTC_CALL_JOINED_PARTICIPANT) AS RTC_CALL_JOINED_PARTICIPANT,\nCOUNT(DISTINCT RTC_CALL_ENDED_PARTICIPANT) AS RTC_CALL_ENDED_PARTICIPANT\nFROM\n(\nSELECT events.ds,\nevents.call_client_session_id,\nevents.appversion,\nevents.deviceid,\nevents.proxy_user_id,\nevents.device_serial_number,\nMAX(events.conference_name) AS conference_name,\nMAX(CASE WHEN event = 'USER_INITIATED_CALL' THEN events.call_client_session_id ELSE NULL END) AS USER_INITIATED_CALL,\nMAX(CASE WHEN event = 'INCALL_UI_ATTACHED_CREATOR' THEN events.call_client_session_id ELSE NULL END) AS INCALL_UI_ATTACHED_CREATOR,\nMAX(CASE WHEN event = 'RTC_USING_CACHED_CONF_NAME' THEN events.call_client_session_id ELSE NULL END) AS RTC_USING_CACHED_CONF_NAME,\nMAX(CASE WHEN event = 'RTC_NOT_USING_CACHED_CONF_NAME' THEN events.call_client_session_id ELSE NULL END) AS RTC_NOT_USING_CACHED_CONF_NAME,\nMAX(CASE WHEN event = 'CONFERENCE_NAME_REQUEST' THEN events.call_client_session_id ELSE NULL END) AS CONFERENCE_NAME_REQUEST,\nMAX(CASE WHEN event = 'CONFERENCE_NAME_RESPONSE' THEN events.call_client_session_id ELSE NULL END) AS CONFERENCE_NAME_RESPONSE,\nMAX(CASE WHEN event = 'CREATE_RTC_CALL_CREATOR' THEN events.call_client_session_id ELSE NULL END) AS CREATE_RTC_CALL_CREATOR,\nMAX(CASE WHEN event = 'CREATE_RTC_CALL_SUCCESS_CREATOR' THEN events.call_client_session_id ELSE NULL END) AS CREATE_RTC_CALL_SUCCESS_CREATOR,\nMAX(CASE WHEN event = 'RTC_CALL_JOINED_CREATOR' THEN events.call_client_session_id ELSE NULL END) AS RTC_CALL_JOINED_CREATOR,\nMAX(CASE WHEN event = 'INVITE_PARTICIPANT_REQUEST' THEN events.call_client_session_id ELSE NULL END) AS INVITE_PARTICIPANT_REQUEST,\nMAX(CASE WHEN event = 'INVITE_PARTICIPANT_RESPONSE' THEN events.call_client_session_id ELSE NULL END) AS INVITE_PARTICIPANT_RESPONSE,\nMAX(CASE WHEN event = 'INVITE_PARTICIPANT_FAILED' THEN events.call_client_session_id ELSE NULL END) AS INVITE_PARTICIPANT_FAILED,\nMAX(CASE WHEN event = 'REMOTE_PARTICIPANT_CONNECTED' THEN events.call_client_session_id ELSE NULL END) AS REMOTE_PARTICIPANT_CONNECTED,\nMAX(CASE WHEN event = 'RTC_CALL_ENDED' THEN events.call_client_session_id ELSE NULL END) AS RTC_CALL_ENDED,\nMAX(CASE WHEN event = 'USER_HANG_UP_CALL' THEN events.call_client_session_id ELSE NULL END) AS USER_HANG_UP_CALL,\nMAX(CASE WHEN event = 'RTC_CALL_ENDED_CREATOR' THEN events.call_client_session_id ELSE NULL END) AS RTC_CALL_ENDED_CREATOR,\nMAX(CASE WHEN event = 'REMOTE_PARTICIPANT_DISCONNECTED' THEN events.call_client_session_id ELSE NULL END) AS REMOTE_PARTICIPANT_DISCONNECTED,\nMAX(CASE WHEN event = 'OMNISTORE_ACTIVE_CALL_REMOVE' THEN events.call_client_session_id ELSE NULL END) AS OMNISTORE_ACTIVE_CALL_REMOVE,\nMAX(CASE WHEN event = 'OMNISTORE_CALL_REJECTED' THEN events.call_client_session_id ELSE NULL END) AS OMNISTORE_CALL_REJECTED,\nMAX(CASE WHEN event = 'OMNISTORE_ACTIVE_CALL_ADD' THEN events.call_client_session_id ELSE NULL END) AS OMNISTORE_ACTIVE_CALL_ADD,\nMAX(CASE WHEN event = 'INCALL_UI_ATTACHED_PARTICIPANT' THEN events.call_client_session_id ELSE NULL END) AS INCALL_UI_ATTACHED_PARTICIPANT,\nMAX(CASE WHEN event = 'CREATE_RTC_CALL_PARTICIPANT' THEN events.call_client_session_id ELSE NULL END) AS CREATE_RTC_CALL_PARTICIPANT,\nMAX(CASE WHEN event = 'CREATE_RTC_CALL_SUCCESS_PARTICIPANT' THEN events.call_client_session_id ELSE NULL END) AS CREATE_RTC_CALL_SUCCESS_PARTICIPANT,\nMAX(CASE WHEN event = 'JOINING_CALL_PARTICIPANT' THEN events.call_client_session_id ELSE NULL END) AS JOINING_CALL_PARTICIPANT,\nMAX(CASE WHEN event = 'RTC_CALL_JOINED_PARTICIPANT' THEN events.call_client_session_id ELSE NULL END) AS RTC_CALL_JOINED_PARTICIPANT,\nMAX(CASE WHEN event = 'RTC_CALL_ENDED_PARTICIPANT' THEN events.call_client_session_id ELSE NULL END) AS RTC_CALL_ENDED_PARTICIPANT\nFROM stg_fct_aloha_calling_events events\nINNER JOIN fct_aloha_calling_actors\nON (events.call_client_session_id = fct_aloha_calling_actors.call_client_session_id\n   AND events.proxy_user_id = fct_aloha_calling_actors.proxy_user_id)\nWHERE events.ds BETWEEN '2018-03-08' AND '2018-03-14'\nAND fct_aloha_calling_actors.ds BETWEEN '2018-03-08' AND '2018-03-14'\nAND fct_aloha_calling_actors.is_initiator\n  \n      \n  \nGROUP BY 1, 2, 3, 4, 5, 6\n) aaa    \nGROUP BY ds, device_serial_number\nORDER BY 1 DESC
snc1_batch	prism_batch	si	20180308_150734_48392_afybh	dataswarm@worker@si.co_igops.offline_classifiers.post_queue_classifiers.pipelines[POST_INDIAN].subtasks[create_feature_table]	/* Generated */\nINSERT INTO stg_classifier_post_indian_scores (\n  "features",\n  "ds"\n)\nSELECT\n  "features",\n  '2018-03-07' AS "ds"\nFROM (\n  /* User-provided */\n  WITH jobs AS (\n  SELECT\n      job_id id,\n      queue_id,\n      IF(\n          REGEXP_LIKE(\n              JSON_EXTRACT_SCALAR(\n                  decision_data,\n                  '$.decision_string'\n              ),\n              '[Ii]gnore'\n          ),\n          'false',\n          'true'\n      ) is_actioned,\n      JSON_EXTRACT_SCALAR(\n          decision_data,\n          '$.decision_string'\n      ) decision\n  FROM fct_job_event:operations\n  WHERE ds = '2018-03-07'\n  AND co_system = 'SRT'\n  AND event = 'close'\n  AND review_system <> 'automation'\n  AND queue_id IN (597055187106338)\n  )\n\n  SELECT\n      JSON_FORMAT(CAST(\n          MAP(\n              ARRAY[\n                  'id',\n                  'queue_id',\n                  'is_actioned',\n                  'decision',\n                  'text'\n              ],\n              ARRAY[\n                  CAST(id AS VARCHAR),\n                  CAST(queue_id AS VARCHAR),\n                  is_actioned,\n                  decision,\n                  text\n              ]\n          )\n          AS JSON\n      )) features\n  FROM (\n      SELECT\n          srt.id,\n          srt.is_actioned,\n          srt.decision,\n          srt.queue_id,\n          REDUCE(\n              MAP_VALUES(\n                  MAP_FILTER(\n                      CAST(JSON_PARSE(dim.job_data) AS MAP<VARCHAR,VARCHAR>),\n                      (k, v) -> k IN ('title','text','description')\n                  )\n              ),\n              '',\n              (i, n) -> CONCAT(i, ' ', n),\n              i -> i\n          ) text\n      FROM dim_single_review_jobs:di dim\n      JOIN jobs srt\n      USING (id, queue_id)\n      WHERE dim.ds = '2018-03-07'\n      AND dim.queue_id IN (597055187106338)\n  )\n)
ftw2_adhoc2	prism	ad_metrics	20180331_101748_98718_rq7f2	unidash:309053469575219:argus:473523	SELECT    \n    module_name,\n    count(distinct user_or_page) as user_count\n    --count(*) as action_count    \nFROM\n\tsmi_core_metrics\nJOIN (\n  SELECT user_account_id\n  FROM smi_user_details\n  WHERE ds = '2018-03-30'\n  AND (json_array_contains('[]', role) OR json_array_length('[]') = 0)\n)\nUSING (user_account_id)\nWHERE\n\tds BETWEEN '2018-03-24' AND '2018-03-30'\n    and ((json_extract_scalar(context_map['OPTIMAL_SOLUTIONS_CONTEXT' ], '$.VIEW') = 'UNDER_DELIVERY') OR at_tool = 'UNDER_DELIVERY')\n              \n    and event_name = 'falcon.graphic_tab_selected'\ngroup by module_name\nORDER BY 2 DESC
ftw2_adhoc3	prism	ad_metrics	20180312_160551_38255_58zw2	argus:argus:510736	SELECT\n\tdate.ds,\n  role,\n  "dap_pct"\nFROM (\n  SELECT\n  \tDATE(dateid) AS ds\n  FROM\n\t\tdim_date:operations\n  WHERE dateid BETWEEN '2017-10-01' AND '2018-06-30'\n  AND weekdayname NOT IN ('Saturday', 'Sunday')\n) date\nLEFT JOIN (\nSELECT \n    case \n         when DAY_OF_WEEK(date(allsales.ds)) = 6 THEN DATE_ADD('day', -1, date(allsales.ds))\n         when DAY_OF_WEEK(date(allsales.ds)) = 7 THEN DATE_ADD('day', -2 , date(allsales.ds))\n         ELSE date(allsales.ds)\n    end as ds,\n    role,\n    COUNT(DISTINCT crm.user_account_id) * 100.0 / COUNT(DISTINCT allsales.user_account_id) AS "dap_pct"\nFROM (\n        SELECT DISTINCT\n            user_account_id,\n            ds,\n            ROLE\n        FROM smi_user_details\n        WHERE ds >= '2017-10-01'\n        \tAND ds <= '2018-03-10'\n  \t\t\t\tAND role IS NOT NULL\n    ) allsales\n    LEFT OUTER JOIN (\n        SELECT\n            ds,\n            user_account_id\n        FROM\n            smi_user_datelist\n        WHERE\n            ds >= '2017-10-01'\n            AND l1_status IN(1, 2, 3)\n            AND event_type = 'actionable visits'\n        GROUP BY\n            1,\n            2\n    ) crm\n    ON allsales.user_account_id = crm.user_account_id\n    AND allsales.ds = crm.ds\nGROUP BY\n    1,\n    2\n) dap\nUSING (ds)
carbon_batch	prism_batch	payments	20180329_051726_16889_di6ar	dataswarm@worker@payments.risk.measurement.ads.risk_false_positive_sampled.generate_bootstraps[machine_7_DATEID2]	/* Generated */\nINSERT INTO risk_false_positive_sampling_results_boot (\n  "total_volume",\n  "replicate",\n  "metric",\n  "num_obs",\n  "sample_type",\n  "ds"\n)\nSELECT\n  "total_volume",\n  "replicate",\n  "metric",\n  "num_obs",\n  'machine_7_DATEID2' AS "sample_type",\n  '2018-03-25' AS "ds"\nFROM (\n  /* User-provided */\n  SELECT\n    replicate,\n    SUM(metric) AS metric,\n    COUNT(1) AS num_obs,\n    total_volume\n  FROM (\n    SELECT\n      exploded.id,\n      exploded.metric,\n      exploded.replicate,\n      total_volume\n    FROM (\n      SELECT\n        weighted.id,\n        weighted.metric,\n        t.weight,\n        t.replicate,\n        total_volume\n      FROM (\n        SELECT\n          base.id,\n          base.metric,\n          CONCAT(\n            -- the first replicate is the original sample metric\n            -- so all weights are set to one\n            ARRAY[1],\n            -- all subsequent replicates are the bootstraps\n            TRANSFORM(\n              SEQUENCE(1, 500),\n              -- samples have a 50% chance of being included with weight of 2\n              -- also have a 50% chance of not being included at all (i.e. weight of 0)\n              x -> IF(\n                FB_NECTAR_SAMPLING_PCT(\n                  CONCAT(CAST(base.id AS VARCHAR), '_', CAST(x AS VARCHAR))\n                ) > 0.5,\n                2,\n                0\n              )\n            )\n          ) AS boot_weights,\n          total_volume\n        FROM (\n\n  SELECT\n    a.id,\n    a.metric,\n    b.total_volume\n  FROM (\n    SELECT\n      CONCAT(CAST(account_id AS VARCHAR), REPLACE(ds, '-')) AS id,\n      COALESCE(is_false_positive, 0) * est_volume AS metric\n    FROM risk_false_positive_sampling_results\n    WHERE\n      ds BETWEEN '2018-03-19' AND '2018-03-25'\n      AND product = 'ads'\n      AND strata = 'machine'\n  ) a\n  JOIN (\n    SELECT\n      CAST(SUM(est_volume) AS BIGINT) AS total_volume\n    FROM risk_false_positive_sampling_results\n    WHERE\n      ds BETWEEN '2018-03-19' AND '2018-03-25'\n      AND product = 'ads'\n      AND strata = 'machine'\n  ) b\n  ON\n    1 = 1\n\n        ) base\n      ) weighted\n      -- we explode sample weights to get one row per id per bootstrap\n      CROSS JOIN\n        UNNEST(boot_weights) WITH ORDINALITY AS t (weight, replicate)\n    ) exploded\n    -- an inner join is used to do the weighted sampling\n    -- if weight = 1 (1st replicate only), the sample is included once\n    -- if weight = 2 (all subsequent replicates), the sample is included twice\n    -- else, the sample is not included\n    JOIN (\n      SELECT\n        weight\n      FROM (\n        -- we include 2 twice here so that those samples appear twice\n        VALUES 1, 2, 2\n      ) AS t (weight)\n    ) sampler\n    USING (weight)\n  )\n  GROUP BY\n    replicate,\n    total_volume\n)
ftw2_batch3	prism_batch	ad_metrics	20180322_071639_41037_yswx3	dataswarm@worker@ad_metrics.buda.create_metrics_master.populate_mego_metrics_master.subtasks[smi_crm_ud_gso_wap_pct]	/* Generated */\nINSERT INTO mego_metrics_master (\n  "id",\n  "domain",\n  "metric_ds",\n  "metric_display_name",\n  "metric_value",\n  "query_namespace",\n  "goal_valid_from_ds",\n  "goal_valid_to_ds",\n  "unit",\n  "goal_start_value",\n  "goal_end_value",\n  "goal_ds",\n  "goal_value",\n  "is_going_over_goal_good",\n  "owner",\n  "owner_unixname",\n  "tags",\n  "tag_names",\n  "metric_desc",\n  "ds",\n  "metric_name"\n)\nSELECT\n  "id",\n  "domain",\n  "metric_ds",\n  "metric_display_name",\n  "metric_value",\n  "query_namespace",\n  "goal_valid_from_ds",\n  "goal_valid_to_ds",\n  "unit",\n  "goal_start_value",\n  "goal_end_value",\n  "goal_ds",\n  "goal_value",\n  "is_going_over_goal_good",\n  "owner",\n  "owner_unixname",\n  "tags",\n  "tag_names",\n  "metric_desc",\n  '2018-03-22' AS "ds",\n  'smi_crm_ud_gso_wap_pct' AS "metric_name"\nFROM (\n  /* User-provided */\n                  SELECT\n                      CAST(9540 AS BIGINT) as id,\n                      'smi_sales_growth' as domain,\n                      A.metric_ds as metric_ds,\n                      'CRM Under Delivery GSO WAP Percentage' as metric_display_name,\n                      A.metric_value * 1.0 as metric_value,\n                      'ad_metrics' as query_namespace,\n                      B.goal_valid_from_ds,\n                      B.goal_valid_to_ds,\n                      'percent' as unit,\n                      B.goal_start_value,\n                      B.goal_end_value,\n                      B.goal_ds,\n                      B.goal_value,\n                      B.is_going_over_goal_good,\n                      '100003516676237' as owner,\n                      SPLIT('zikang', ',')\n                          as owner_unixname,\n                      'SMI{CHAR_NEWLINE}CRM{CHAR_NEWLINE}Sales Growth{CHAR_NEWLINE}2018 H1{CHAR_NEWLINE}Goal' as tags,\n                      SPLIT('SMI{CHAR_NEWLINE}CRM{CHAR_NEWLINE}Sales Growth{CHAR_NEWLINE}2018 H1{CHAR_NEWLINE}Goal', '{CHAR_NEWLINE}')\n                          as tag_names,\n                      metric_desc,\n                      '2018-03-22' AS ds,\n                      'smi_crm_ud_gso_wap_pct' as metric_name\n                  FROM\n                      (SELECT\n      *\n  FROM (\n      WITH\n      date AS (\n          SELECT\n              dateid\n          FROM\n              dim_date:operations\n          WHERE\n              dateid BETWEEN '2017-10-01' AND '2018-03-22'\n      ),\n      user AS (\n          SELECT\n              ds,\n              user_account_id\n          FROM\n              smi_user_details\n          WHERE\n              role = 'CSM'\n              AND ds BETWEEN '2017-09-25' AND '2018-03-22'\n      ),\n      user_count AS (\n          SELECT\n              dateid AS ds,\n              COUNT(DISTINCT user_account_id) AS user_count\n          FROM\n              date\n              LEFT JOIN user\n              ON DATE_DIFF('day', CAST(ds AS DATE), CAST(dateid AS DATE)) BETWEEN 0 AND 6\n          WHERE\n              dateid <= '2018-03-20'\n          GROUP BY\n              1\n      ),\n      active AS (\n          SELECT\n              ds,\n              user_account_id\n          FROM\n              smi_crm_persist\n          WHERE\n              ((at_tool = 'OPTIMAL_SOLUTIONS' AND json_extract_scalar(context_map['OPTIMAL_SOLUTIONS_CONTEXT' ], '$.VIEW') = 'UNDER_DELIVERY') OR at_tool = 'UNDER_DELIVERY')\n              AND event_name NOT LIKE ('%load_%')\n              AND godmode_id IS NULL\n              AND ds BETWEEN '2017-09-25' AND '2018-03-22'\n          GROUP BY\n              ds,\n              user_account_id\n      ),\n      active_count AS (\n          SELECT\n              dateid AS ds,\n              COALESCE(COUNT(DISTINCT active.user_account_id), 0) AS active_count\n          FROM\n              active\n              JOIN user\n              ON active.ds = user.ds AND active.user_account_id = user.user_account_id\n              RIGHT JOIN date\n              ON DATE_DIFF('day', CAST(active.ds AS DATE), CAST(dateid AS DATE)) BETWEEN 0 AND 6\n          GROUP BY\n              1\n      )\n      SELECT\n          active_count.ds AS metric_ds,\n          SUM(active_count) AS active_count,\n          SUM(user_count) AS user_count,\n          SUM(active_count) * 1.0 / SUM(user_count) AS metric_value\n      FROM\n          active_count\n          LEFT JOIN user_count USING (ds)\n      WHERE\n          active_count.ds BETWEEN '2017-10-01'\n          AND '2018-03-22'\n      GROUP BY\n          1\n  )\r\n  ) A\n                  LEFT OUTER JOIN\n                      mego_goals_master B\n                      ON B.ds = '2018-03-22'\n                      AND B.start_executing_metric_query = 1\n                      AND B.query_namespace = 'ad_metrics'\n                      AND B.id = CAST(9540 AS BIGINT)\n                      AND B.metric_name = 'smi_crm_ud_gso_wap_pct'\n                      AND B.goal_ds = A.metric_ds\n                  WHERE\n                      A.metric_value is not null\n)
atn3_batch3	prism_batch	search	20180328_080636_21501_5q4dy	dataswarm@worker@search.query_similarity.query_clustering.insert_query_summary[search_lsh_v1]	/* Generated */\nINSERT INTO search_query_cluster_assignments (\n  "query_id",\n  "query",\n  "cluster_info",\n  "ds",\n  "method"\n)\nSELECT\n  "query_id",\n  "query",\n  "cluster_info",\n  '2018-03-27' AS "ds",\n  'search_lsh_v1' AS "method"\nFROM (\n  /* User-provided */\n  WITH embedding_counts AS (\n      -- Count number of queries with identical embeddings, per method\n      SELECT\n          FROM_BIG_ENDIAN_64(\n              XXHASH64(\n                  TO_UTF8(\n                      JSON_FORMAT(CAST(embedding AS JSON))\n                  )\n              )\n          ) AS embedding_id,\n          COUNT(1) AS queries_with_embedding\n      FROM search_query_embeddings_bucketed\n      WHERE ds = '2018-03-27'\n          -- LSH are a special case where the embedding is the cluster_id\n          AND method = 'search_lsh_v1'\n      GROUP BY 1\n  ), embeddings_with_query AS (\n      -- Sometimes we have the query already, in that case just pull it\n      SELECT a.method,\n          a.query_id,\n          a.query,\n          FROM_BIG_ENDIAN_64(\n              XXHASH64(\n                  TO_UTF8(\n                      JSON_FORMAT(CAST(a.embedding AS JSON))\n                  )\n              )\n          ) AS embedding_id\n      FROM search_query_embeddings_bucketed a\n      WHERE a.method = 'search_lsh_v1'\n          AND a.ds = '2018-03-27'\n          AND a.query IS NOT NULL\n  ), embeddings_without_query AS (\n      -- For some embeddings, we have lost track of the query.  Get it.\n      SELECT a.method,\n          a.query_id,\n          b.query,\n          FROM_BIG_ENDIAN_64(\n              XXHASH64(\n                  TO_UTF8(\n                      JSON_FORMAT(CAST(a.embedding AS JSON))\n                  )\n              )\n          ) AS embedding_id\n      FROM search_query_embeddings_bucketed a\n          LEFT OUTER JOIN (\n              SELECT query_id,\n                  query\n              FROM stg_search_query_embeddings\n              WHERE ds = '2018-03-27'\n          ) b USING(query_id)\n      WHERE a.query IS NULL\n          AND a.method = 'search_lsh_v1'\n          AND a.ds = '2018-03-27'\n  ), unioned AS (\n      -- These should be MECE, and encompass the original set\n      SELECT * FROM embeddings_with_query\n      UNION ALL\n      SELECT * FROM embeddings_without_query\n  )\n  SELECT\n      a.query_id,\n      a.query,\n      MAP(\n          ARRAY[\n              'cluster_id',\n              'sub_cluster_id',\n              'sub_cluster_size',\n              'distance'\n          ],\n          ARRAY[\n              COALESCE(\n                  CAST(b.cluster_id AS DOUBLE),\n                  CAST(a.embedding_id AS DOUBLE)\n              ),\n              CAST(a.embedding_id AS DOUBLE),\n              CAST(c.queries_with_embedding AS DOUBLE),\n              b.distance\n          ]\n      ) AS cluster_info\n  FROM unioned a\n      LEFT OUTER JOIN (\n          SELECT query_id,\n              cluster_id,\n              distance\n          FROM search_query_clusters_bucketed\n          WHERE ds = '2018-03-27'\n              AND method = 'search_lsh_v1'\n      ) b ON a.query_id = b.query_id\n      INNER JOIN embedding_counts c\n          ON a.embedding_id = c.embedding_id\n)
atn2_batch1	prism_batch	messages	20180331_125739_08484_sqgdm	dataswarm@worker@messages.workplace.workplace_message_sends.deltoid[workplace_message_sends_deltoid]	CREATE TABLE IF NOT EXISTS workplace_message_sends_deltoid (\n    userid    BIGINT\n        COMMENT 'The result of calling getUserID on a supplied ViewerContext. This could be a person''s ID, a page''s, or an application''s. If you only want the person behind the page or app, you want the ''accountid'' field.',\n    user_company_id    BIGINT\n        COMMENT 'The workplace company ID for the sending user',\n    recipient_userid    BIGINT\n        COMMENT 'FBID of the other user for canonical threads only',\n    rid_for_userid    BIGINT\n        COMMENT 'The Clementine RID for this UserID, if exists.',\n    thread_fbid    BIGINT\n        COMMENT 'FBID of the thread, group threads only',\n    mid    VARCHAR\n        COMMENT 'Server side unique ID of the message.  Not an FBID.',\n    offline_threading_id    BIGINT\n        COMMENT 'Client side generated unique ID for a message, not an FBID',\n    conformed_interface    VARCHAR\n        COMMENT 'Conformed interface based on the columns: interface, mobile_app_id, messaging_app_id',\n    interface    VARCHAR\n        COMMENT 'Messaging interface (such as Web Chat)',\n    mobile_app_id    BIGINT\n        COMMENT 'The ID number of the mobile app',\n    mobile_app_version    VARCHAR\n        COMMENT 'The version number of the mobile app (as a VARCHAR)',\n    messaging_app_id    BIGINT\n        COMMENT 'AppID of the messaging request, slightly different from canonical',\n    attribution_app_id    BIGINT\n        COMMENT 'AppID of the Messenger Platform app',\n    device_instance_id    VARCHAR\n        COMMENT 'HashID representing a collection of Device data. You can use this to join on honey_mobile_device.hashid:mobile. (this column used to be called ''mobile_hashid'', but is now called ''device_instance_id''.)',\n    genie_id    BIGINT\n        COMMENT 'GenieID: the message will appear to be sent by this genie in Messenger',\n    user_agent    VARCHAR\n        COMMENT 'The UserAgent field from a user''s browser',\n    source    VARCHAR\n        COMMENT 'Source of the message',\n    code_sender    VARCHAR\n        COMMENT 'Where the send originated from (which endpoint)',\n    browser    VARCHAR\n        COMMENT 'The user browser',\n    device_os    VARCHAR\n        COMMENT 'The operating system of the mobile device',\n    device_os_version    VARCHAR\n        COMMENT 'The os version of the mobile device',\n    carrier    VARCHAR\n        COMMENT 'The name of the carrier that the user''s phone is using.',\n    joinable_mode    BIGINT\n        COMMENT 'joinable mode for the group',\n    body_length    BIGINT\n        COMMENT 'Length of the message',\n    body_words    BIGINT\n        COMMENT 'Words of the message',\n    body_unique_words    BIGINT\n        COMMENT 'Unique words of the message',\n    detected_dialect    VARCHAR\n        COMMENT 'Detected dialect of the message body',\n    detected_dialect_confidence    BIGINT\n        COMMENT 'Confidence of detected_dialect',\n    first_attachment_type    VARCHAR\n        COMMENT 'Type of first attachment (i.e. sticker, photo, etc)',\n    sender_fbtype    BIGINT\n        COMMENT 'FBType of the sender (person or page)',\n    sender_accountstatus    BIGINT\n        COMMENT 'Account status of sender',\n    sender_presence    VARCHAR\n        COMMENT 'Presence of sender at time of send',\n    recipient_accountstatus    BIGINT\n        COMMENT 'Account status of recipient',\n    ip_address    VARCHAR\n        COMMENT 'the IP address from which the user actually accessed Facebook.',\n    ip_country    VARCHAR\n        COMMENT 'The country the request originated from, determined from IP.',\n    first_tags    VARCHAR\n        COMMENT 'Adhoc tags, can really be anything. Example: last clicked UI element.',\n    ttl    BIGINT\n        COMMENT 'TTL for ephemeral messages',\n    code_path    VARCHAR\n        COMMENT 'The SendMessageCodePath of the message',\n    first_xmd_keys    VARCHAR\n        COMMENT 'Set of keys present in the extensible message data map. These are values that are added to the message through XMD builders.',\n    server_timestamp    BIGINT\n        COMMENT 'Timestamp at send time',\n    event_time    DOUBLE\n        COMMENT 'The webserver timestamp at the moment that log() was called.',\n    ts    VARCHAR\n        COMMENT 'Timestamp at which the Hive loader ran (loosely related to when the data rows were generated)',\n    ds    VARCHAR\n)\nCOMMENT 'Deltoid safe version of the table workplace_message_sends:messages. Created by WTF Framework.'\nWITH (\n    PARTITIONED_BY = ARRAY['ds'],\n    RETENTION_DAYS = 30\n)
snc1	prism	notifications	20180329_072727_25137_2nhjz	daiquery_metadata	EXPLAIN (TYPE VALIDATE) --select recipid,sender_name,count(distinct name) from georgy_notified_nonfollower_audiences group by 1,2 having count(distinct name)>1\n\nselect sender_name,target_page,sum(conversions),sum(seen),100.0*sum(conversions)/sum(seen) as ctr\nfrom\n(\nselect a.recipid,a.sender_name,case when audiences=1 then name when audiences=2 then '2 audiences' when audiences=3 then '3 audiences' else '4+ audiences' end as target_page,conversions,seen\nfrom \ngeorgy_notified_nonfollower_audiences a\njoin\n(select ds,sender_name,recipid,count(distinct name) as audiences from georgy_notified_nonfollower_audiences group by 1,2,3) aud\nusing (ds,sender_name,recipid)\ngroup by 1,2,3,4,5\n) \ngroup by 1,2
carbon_batch	prism_batch	payments	20180329_051728_16906_di6ar	dataswarm@worker@payments.risk.measurement.ads.risk_false_positive_sampled.generate_bootstraps[cluster_7_DATEID14]	/* Generated */\nINSERT INTO risk_false_positive_sampling_results_boot (\n  "total_volume",\n  "replicate",\n  "metric",\n  "num_obs",\n  "sample_type",\n  "ds"\n)\nSELECT\n  "total_volume",\n  "replicate",\n  "metric",\n  "num_obs",\n  'cluster_7_DATEID14' AS "sample_type",\n  '2018-03-13' AS "ds"\nFROM (\n  /* User-provided */\n  SELECT\n    replicate,\n    SUM(metric) AS metric,\n    COUNT(1) AS num_obs,\n    total_volume\n  FROM (\n    SELECT\n      exploded.id,\n      exploded.metric,\n      exploded.replicate,\n      total_volume\n    FROM (\n      SELECT\n        weighted.id,\n        weighted.metric,\n        t.weight,\n        t.replicate,\n        total_volume\n      FROM (\n        SELECT\n          base.id,\n          base.metric,\n          CONCAT(\n            -- the first replicate is the original sample metric\n            -- so all weights are set to one\n            ARRAY[1],\n            -- all subsequent replicates are the bootstraps\n            TRANSFORM(\n              SEQUENCE(1, 500),\n              -- samples have a 50% chance of being included with weight of 2\n              -- also have a 50% chance of not being included at all (i.e. weight of 0)\n              x -> IF(\n                FB_NECTAR_SAMPLING_PCT(\n                  CONCAT(CAST(base.id AS VARCHAR), '_', CAST(x AS VARCHAR))\n                ) > 0.5,\n                2,\n                0\n              )\n            )\n          ) AS boot_weights,\n          total_volume\n        FROM (\n\n  SELECT\n    a.id,\n    a.metric,\n    b.total_volume\n  FROM (\n    SELECT\n      CONCAT(CAST(account_id AS VARCHAR), REPLACE(ds, '-')) AS id,\n      COALESCE(is_false_positive, 0) * est_volume AS metric\n    FROM risk_false_positive_sampling_results\n    WHERE\n      ds BETWEEN '2018-03-07' AND '2018-03-13'\n      AND product = 'ads'\n      AND strata = 'cluster'\n  ) a\n  JOIN (\n    SELECT\n      CAST(SUM(est_volume) AS BIGINT) AS total_volume\n    FROM risk_false_positive_sampling_results\n    WHERE\n      ds BETWEEN '2018-03-07' AND '2018-03-13'\n      AND product = 'ads'\n      AND strata = 'cluster'\n  ) b\n  ON\n    1 = 1\n\n        ) base\n      ) weighted\n      -- we explode sample weights to get one row per id per bootstrap\n      CROSS JOIN\n        UNNEST(boot_weights) WITH ORDINALITY AS t (weight, replicate)\n    ) exploded\n    -- an inner join is used to do the weighted sampling\n    -- if weight = 1 (1st replicate only), the sample is included once\n    -- if weight = 2 (all subsequent replicates), the sample is included twice\n    -- else, the sample is not included\n    JOIN (\n      SELECT\n        weight\n      FROM (\n        -- we include 2 twice here so that those samples appear twice\n        VALUES 1, 2, 2\n      ) AS t (weight)\n    ) sampler\n    USING (weight)\n  )\n  GROUP BY\n    replicate,\n    total_volume\n)
baldr_atn2	raptor	baldr	20180330_021837_14813_zui4p	baldr:deltoid3_ui_test:12d3ce1f82bb4f72be291acb932a249a	SELECT\n    AVG(IF("aggregation" > "winsorization_alias", "winsorization_alias", "aggregation")) AS "winsorized_mean",\n    VARIANCE(IF("aggregation" > "winsorization_alias", "winsorization_alias", "aggregation")) AS "winsorized_var",\n    COUNT(IF("aggregation" > "winsorization_alias", "winsorization_alias", "aggregation")) AS "count_nonnull",\n    COUNT(IF("aggregation" != 0, "aggregation")) AS "count_nonzero",\n    "metrics"."md_scenario" AS "md_scenario",\n    "metrics"."md_metric_name" AS "md_metric_name",\n    "condition" AS "condition"\nFROM (\n    SELECT\n        "metrics"."unitid" AS "unitid",\n        SUM("metrics"."metric_value") AS "aggregation",\n        COALESCE(CAST("metrics"."md_scenario" AS VARCHAR), '<null_column>') AS "md_scenario",\n        COALESCE(CAST("metrics"."md_metric_name" AS VARCHAR), '<null_column>') AS "md_metric_name",\n        "population"."condition" AS "condition"\n    FROM baldr.hive_ad_interfaces metrics\n    INNER JOIN (\n        SELECT\n            "fbid" AS "fbid",\n            "condition" AS "condition",\n            MIN("time") AS "time"\n        FROM (\n            SELECT\n                "fbid" AS "fbid",\n                "condition" AS "condition",\n                GREATEST("time", "ds") AS "time"\n            FROM baldr.gk_first_exposures baldr_gk_first_exposures\n            WHERE (GREATEST("time", "ds") < TIMESTAMP '2018-03-28 00:00:00' AND ("restraint" = 'flowmin_rc_var_reusing_public_v4' AND "name" = 'makehaste_min_rc') AND "condition" IN ('testing', 'control'))\n        ) first_exposures_query\n        GROUP BY\n            "fbid", "condition"\n    ) population\n    ON "metrics"."unitid" = "population"."fbid"\n    WHERE ("metrics"."time" >= TIMESTAMP '2018-03-21 00:00:00' AND "metrics"."time" < TIMESTAMP '2018-03-28 00:00:00' AND "metrics"."unitid" != 0 AND "metrics"."unitid" IS NOT NULL AND "metrics"."md_metric_name" = ('scenario_duration'))\n    GROUP BY\n        "metrics"."unitid", "metrics"."md_scenario", "metrics"."md_metric_name", "population"."condition"\n) metrics\nINNER JOIN ((VALUES ('scenario_duration', 'page_load', 5119), ('scenario_duration', 'page_load_all', 8191), ('scenario_duration', 'page_load_visible_rows', 8191), ('scenario_duration', 'table_insights_data_load', 4095), ('scenario_duration', 'table_insights_body_dd', 5631), ('scenario_duration', 'table_insights_footer_dd', 11263), ('scenario_duration', 'insightsTable.loadFooter', 10751), ('scenario_duration', 'data_plan', 127), ('scenario_duration', 'campaign_display_any', 60), ('scenario_duration', 'campaign_display_all', 47), ('scenario_duration', 'objective_selector_interaction', 2047), ('scenario_duration', 'change_level_dd', 2047), ('scenario_duration', 'ASSIGNED_PAGES_display', 1279), ('scenario_duration', 'ASSIGNED_AD_ACCOUNTS_display', 1535), ('scenario_duration', 'delivery_estimate_api_response_time', 3071), ('scenario_duration', 'adgroup_preview_load', 15359), ('scenario_duration', 'MTC_TTI', 55), ('scenario_duration', 'AdsCommonTargetingLanguagesEditor_did_mount', 239), ('scenario_duration', 'AdsCommonTargetingLocationEditorV2_did_finish_loading_entries', 2815), ('scenario_duration', 'MTC_did_mount', 2815), ('scenario_duration', 'AdsCommonTargetingAgeEditor_did_mount', 191), ('scenario_duration', 'AdsCommonTargetingGenderEditor_did_mount', 191), ('scenario_duration', 'AdsCommonTargetingAudienceEditor_did_mount', 223), ('scenario_duration', 'AdsCommonTargetingAudienceEditor_did_finish_loading_entries', 511), ('scenario_duration', 'AdsCommonTargetingConnectionsEditor_did_finish_loading_entries', 511), ('scenario_duration', 'AdsUnifiedFlexibleTargetingEditor_did_finish_loading_entries', 1023), ('scenario_duration', 'stepper_init_start', 463), ('scenario_duration', 'stepper_render_views', 543), ('scenario_duration', 'reach_estimate_load_time', 3199), ('scenario_duration', 'publish', 9215), ('scenario_duration', 'ALERT_display', 6143), ('scenario_duration', 'EXTENDED_CREDIT_AUTOMATION_display', 6143), ('scenario_duration', 'editor_l1_dd', 2687), ('scenario_duration', 'open_ad_object_dd', 1791), ('scenario_duration', 'page_transition', 511), ('scenario_duration', 'editor_l2_targeting_cold_start', 511), ('scenario_duration', 'editor_l2_saved_audiences_cold_start', 511), ('scenario_duration', 'editor_l2_cold_start', 607), ('scenario_duration', 'editor_l2_delivery_cold_start', 543), ('scenario_duration', 'adset_load_all', 607), ('scenario_duration', 'editor_l2_placements_cold_start', 383), ('scenario_duration', 'adset_load_any', 60), ('scenario_duration', 'DELIVERY_CONTAINER_CREATE_FLOW_DD', 35), ('scenario_duration', 'AdsDeliveryAdvancedSection_DD', 255), ('scenario_duration', 'AdsDeliveryScheduleEditor_DD', 191), ('scenario_duration', 'AdsDeliveryBudgetEditor_DD', 191), ('scenario_duration', 'AdsDeliveryEventTypeEditor_DD', 511), ('scenario_duration', 'AdsDeliveryFrequencyControlIntervalEditor_DD', 543), ('scenario_duration', 'AdsDeliveryOptimizationGoalEditor_DD', 639), ('scenario_duration', 'AdsDeliveryBiddingEditor_DD', 639), ('scenario_duration', 'AdsDeliveryTypeEditor_DD', 511), ('scenario_duration', 'AdsDeliveryDayPartingEditor_DD', 511), ('scenario_duration', 'DELIVERY_CONTAINER_OPTIMIZATION_DD', 255), ('scenario_duration', 'editor_l2_saved_audiences', 1407), ('scenario_duration', 'editor_l2_basic_delivery', 1535), ('scenario_duration', 'editor_l2_placements', 1535), ('scenario_duration', 'editor_l2_delivery', 1535), ('scenario_duration', 'editor_l2_targeting', 1919), ('scenario_duration', 'AdsManagementDeliveryScheduleEditor_DD', 511), ('scenario_duration', 'editor_l2', 2047), ('scenario_duration', 'DELIVERY_CONTAINER_BUDGET_SCHEDULE_DD', 351), ('scenario_duration', 'AdsManagementDeliveryLineNumberEditor_DD', 479), ('scenario_duration', 'AdsManagementDeliveryBudgetEditor_DD', 511), ('scenario_duration', 'AdsManagementDeliveryLinePriceEditor_DD', 479), ('scenario_duration', 'AdsManagementDeliveryImpressionLimitEditor_DD', 511), ('scenario_duration', 'AdsDeliveryBudgetReachCurveSection_DD', 831), ('scenario_duration', 'page_load_visible_cells', 1023), ('scenario_duration', 'INSTANT_RISK_display', 6143), ('scenario_duration', 'ad_display_all', 2047), ('scenario_duration', 'ad_display_any', 39), ('scenario_duration', 'editor_l3', 255), ('scenario_duration', 'account_overview.kpi.load', 511), ('scenario_duration', 'account_overview.objective.load', 575), ('scenario_duration', 'account_overview.time.load', 639), ('scenario_duration', 'account_overview.location.load', 767), ('scenario_duration', 'charts', 447), ('scenario_duration', 'charts_view', 2047), ('scenario_duration', 'biz_settings_fetch_data', 5631), ('scenario_duration', 'biz_settings_people_list_rendering', 95), ('scenario_duration', 'charts_performance_single', 895), ('scenario_duration', 'change_date_range_dd', 767), ('scenario_duration', 'SUCCESS_display_all', 87), ('scenario_duration', 'SUCCESS_display_any', 79), ('scenario_duration', 'account_overview.age_gender.load', 703), ('scenario_duration', 'change_sort_dd', 959), ('scenario_duration', 'open_duplication_dialog', 447), ('scenario_duration', 'insights.fetchMetadataEdgeInsights', 1407), ('scenario_duration', 'activity_history', 447), ('scenario_duration', 'SETUP_GUIDE_display', 4095), ('scenario_duration', 'image_upload_drag_dialog', 1663), ('scenario_duration', 'activity_history_view', 1279), ('scenario_duration', 'audience.audience_graphAPI_filter_flow', 255), ('scenario_duration', 'audience.audience_manager_loaded', 895), ('scenario_duration', 'quick_draft_load', 223), ('scenario_duration', 'SECURITY_CHECK_display', 6399), ('scenario_duration', 'charts_demographics', 127), ('scenario_duration', 'image_upload', 703), ('scenario_duration', 'help_tray_article_viewing_time', 1215), ('scenario_duration', 'charts_placement', 127), ('scenario_duration', 'insightsTable.openColumnSetEditor', 575)) AS winsorization_join ("md_metric_name", "md_scenario", "winsorization_alias"))\nON ("metrics"."md_scenario" = "winsorization_join"."md_scenario" AND "metrics"."md_metric_name" = "winsorization_join"."md_metric_name")\nGROUP BY\n    "metrics"."md_scenario", "metrics"."md_metric_name", "condition"\nORDER BY\n    COUNT(1) DESC
de4ftw2	raptor	de	20180330_202508_14262_35b59	unidash:228208741252672:argus:514470	with\nteams as (\n    select \n        r.field0 as team,\n        r.field1 as SCR_goal,\n  \t\t\tr.field2 as holdout_deltoid3_link,\n  \t\t\t100.0*CAST(\n          REGEXP_EXTRACT(r.field3, '^([\\-0-9.]+)', 1)\n          AS DOUBLE\n        ) as holdout_scr_impact,\n  \t\t\t100.0*CAST(\n          REGEXP_EXTRACT(r.field3, '([0-9.]+)$', 1)\n          AS DOUBLE\n        ) as holdout_scr_impact_ci\n    from (    \n        select\n            ARRAY [\n                ('Overall', 7, '', ''),\n                ('Posts', 0.5, '', 'NULL'),\n                ('People', 0.3, '', 'NULL'),\n                ('Social', 0.25, '', 'NULL'),\n                ('Groups', 0.5, '', 'NULL'),\n                ('Links', 1.0, '', 'NULL'),\n                ('Places', 0.5, '', 'NULL'),\n                ('Photos', 0.2, '', 'NULL'),\n                ('WPR', 1.0, '', 'NULL'),\n                ('Pages', 1.75, '', 'NULL'),\n                ('Speed', 1.0, '', 'NULL'),\n                ('TA', 0, '', 'NULL'),\n                ('QR', 1, '', 'NULL'),\n                ('QU', 1, '', ''),\n                ('Connections Product', 0.25, '', 'NULL'),\n                ('Systems Product', 1, '', 'NULL'),\n                ('i18n', 2, '', 'NULL'),\n                ('Others', 0, '', 'NULL')\n            ]\n        as arr\n    )\n    cross join unnest(arr) as t(r)    \n), launch_impact AS (\n    SELECT\n        MAP_VALUES(CAST(m.v['teams'] AS MAP<VARCHAR, VARCHAR>)) AS teams,\n        CAST(m.v['metric'] AS VARCHAR) AS metric,\n        CAST(m.v['name'] AS VARCHAR) AS name,\n        CAST(m.v['launch_date'] AS VARCHAR) AS launch_date,\n        CAST(m.v['movement'] AS DOUBLE) AS movement,\n        CAST(m.v['scaling_reference'] AS VARCHAR) AS scaling_reference\n    FROM (\n        SELECT CAST(JSON_PARSE('{"56": {"is_unique": true, "name": "Add Time Between Reformulations as a feature in WPRs models", "scaling_reference": "https://fburl.com/8ye1zhkz", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "WPR"}, "launch_date": "2017-12-22", "movement": 0.07}, "54": {"is_unique": true, "name": "Local Public Posts V0", "scaling_reference": "https://fburl.com/5t85tkaz", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2017-12-21", "movement": 0.04}, "42": {"is_unique": true, "name": "Relax SERP filtering criteria in sparse sessions", "scaling_reference": "https://fburl.com/teozx9a9", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "WPR"}, "launch_date": "2017-11-22", "movement": 0.08}, "48": {"is_unique": true, "name": "Change the way Android Crash Recovery is Handled for Search", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/520591438310658/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-12-11", "movement": 0.08}, "43": {"is_unique": true, "name": "Increase triggering rate for public photo sub-request", "scaling_reference": "https://fburl.com/npfok9yv", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Photos"}, "launch_date": "2017-11-21", "movement": 0.05}, "60": {"is_unique": true, "name": "Migrate Dynamic Duo rebucketing to WPR", "scaling_reference": "https://fb.alpha.facebook.com/groups/485751768140110/permalink/1806771159371491/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "WPR"}, "launch_date": "2018-02-26", "movement": 0.24}, "61": {"is_unique": true, "name": "Offensive filters on Public Posts subrequests", "scaling_reference": "https://fburl.com/1mx67e6e", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2018-03-06", "movement": -0.05}, "62": {"is_unique": true, "name": "1st Stage Relevance Model Refreshing and Weight Tuning", "scaling_reference": "https://fburl.com/rn6fq9jk", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2018-03-05", "movement": 0.05}, "63": {"is_unique": true, "name": "Downranking offtopic posts in 2nd stage for public posts", "scaling_reference": "https://fburl.com/sieacyud", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2018-03-02", "movement": 0.05}, "64": {"is_unique": true, "name": "High Engaged <query, video-id> mining/generation for retrieval/ranking", "scaling_reference": "https://fburl.com/uvqw01tm", "metric": "search:core:accounting:ratios:content_click_rate", "teams": {"0": "Videos"}, "launch_date": "2018-03-09", "movement": 0.37}, "49": {"is_unique": true, "name": "People entity on empty profile search result page", "scaling_reference": "https://fburl.com/nf52h1li", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Social"}, "launch_date": "2017-12-01", "movement": 0.01}, "52": {"is_unique": true, "name": "Junkiness model experiments for ar_AR", "scaling_reference": "https://fburl.com/pshxbcn7", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-12-27", "movement": 0.02}, "53": {"is_unique": true, "name": "Retrained junkiness model with new features, refresh data and limited random samples", "scaling_reference": "https://fburl.com/89m6yi9v", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-12-18", "movement": 0.04}, "24": {"is_unique": true, "name": "Remove Global Match Demotion Rule from User SERP Model", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/500430690326733/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-10-19", "movement": 0.04}, "25": {"is_unique": true, "name": "Replace entities with general kw", "scaling_reference": "https://fburl.com/5ct0cbes", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "TA"}, "launch_date": "2017-10-19", "movement": 0.08}, "26": {"is_unique": true, "name": "Autocorrection model with realtime", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/481886758847793/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "QU"}, "launch_date": "2017-09-06", "movement": 0.06}, "27": {"is_unique": true, "name": "Serp Speller Model with Online Data c(en_US)", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/502247606811708/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "QR"}, "launch_date": "2017-10-30", "movement": 0.03}, "20": {"is_unique": true, "name": "iOS dense rendering scoped", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/474271756275960/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Social"}, "launch_date": "2017-08-11", "movement": 0.02}, "21": {"is_unique": true, "name": "iOS scoped search enable filters", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/476024982767304", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Social"}, "launch_date": "2017-08-21", "movement": 0.004}, "22": {"is_unique": true, "name": "Junky User Suppression for Non-people", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/484865405216595/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-09-11", "movement": 0.14}, "23": {"is_unique": true, "name": "Improve people for grammar queries", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/485276965175439/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-10-15", "movement": 0.02}, "46": {"is_unique": true, "name": "Retrained junkiness model with clickstream features", "scaling_reference": "https://fburl.com/v4z9gkz1", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-12-05", "movement": 0.08}, "47": {"is_unique": true, "name": "Enabling prefix matches for all tokens", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/507451459624656/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-10-12", "movement": 0.02}, "44": {"is_unique": true, "name": "Unglue OPINION to NEWS", "scaling_reference": "https://fburl.com/ioywqdxi", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "WPR"}, "launch_date": "2017-11-29", "movement": 0.05}, "45": {"is_unique": true, "name": "English speller for ROW", "scaling_reference": "https://fburl.com/92kcvvqk", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "QR"}, "launch_date": "2017-11-29", "movement": 0.01}, "28": {"is_unique": true, "name": "Related searches for i18n", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/481854442184358/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "i18n"}, "launch_date": "2017-09-06", "movement": 0.09}, "29": {"is_unique": true, "name": "WWW finite SERP", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/469426173427185/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2017-08-04", "movement": 0.04}, "40": {"is_unique": true, "name": "Floating \\"One\\" Public Posts Module", "scaling_reference": "https://fburl.com/f5yhbo7o", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2017-11-21", "movement": 0.1}, "41": {"is_unique": true, "name": "1st stage click model for public posts", "scaling_reference": "https://fburl.com/lkn9qovk", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2017-11-17", "movement": 0.05}, "1": {"is_unique": true, "name": "MSL i18n BackTest", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/494280204275115/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"1": "Posts", "0": "i18n"}, "launch_date": "2017-09-28", "movement": 0.1}, "0": {"is_unique": true, "name": "SparseNN public posts", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/462364874133315/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2017-07-17", "movement": 0.21}, "3": {"is_unique": true, "name": "SparseNN Online Model for Public Posts", "scaling_reference": "https://fb.facebook.com/groups/485751768140110/permalink/1755609057821035/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2018-01-16", "movement": 0.05}, "2": {"is_unique": true, "name": "Dynamic Rescoring for SparseNN in Public Posts", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/502260733477062/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Posts"}, "launch_date": "2017-10-27", "movement": 0.04}, "5": {"is_unique": true, "name": "Top Relevant Pages for Tail Queries from NLP", "scaling_reference": "https://fburl.com/xgt6knyg", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-09-14", "movement": 0.04}, "4": {"is_unique": true, "name": "Pages module from posts", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/476034816099654/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"1": "Posts", "0": "Pages"}, "launch_date": "2017-08-18", "movement": 0.1}, "7": {"is_unique": true, "name": "Streamline probability of click model", "scaling_reference": "https://fburl.com/zo5eqdq0", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-10-17", "movement": 0.15}, "6": {"is_unique": true, "name": "Use Recent Interactions for Retrieval", "scaling_reference": "https://fburl.com/whc0uzze", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-10-13", "movement": 0.01}, "9": {"is_unique": true, "name": "Click modeling for photos with sparseNN", "scaling_reference": "https://fb.facebook.com/groups/485751768140110/permalink/1584654378249838/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Photos"}, "launch_date": "2017-08-30", "movement": 0.03}, "8": {"is_unique": true, "name": "Enable Query optionalization for groups", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/486801885022947/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Groups"}, "launch_date": "2017-09-19", "movement": 0.05}, "51": {"is_unique": true, "name": "User 2nd Stage Ranker V2", "scaling_reference": "https://fburl.com/8gvizae8", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-12-08", "movement": 0.05}, "39": {"is_unique": true, "name": "Blended Related Searches", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/507454069624395/?comment_id=508202282882907&comment_tracking=%7B%22tn%22%3A%22R%22%7D", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "QR"}, "launch_date": "2017-11-06", "movement": 0.01}, "65": {"is_unique": true, "name": "Pages Search: L2 Ranker - Backtest Followup", "scaling_reference": "https://fburl.com/prv3a0e5", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2018-03-08", "movement": 0.16}, "38": {"is_unique": true, "name": "Add long term batch counters and result level counters to public photo 2nd stage click model", "scaling_reference": "https://fburl.com/56h5v0hn", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Photos"}, "launch_date": "2017-11-10", "movement": 0.04}, "59": {"is_unique": true, "name": "Content-based Pages Retrieval", "scaling_reference": "https://fburl.com/4ghcfu1p", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2018-02-16", "movement": 0.14}, "58": {"is_unique": true, "name": "Scoped Search Experience Updates - Android", "scaling_reference": "https://fburl.com/3q95hhm8", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Social"}, "launch_date": "2018-01-26", "movement": -0.04}, "11": {"is_unique": true, "name": "Improved WPR model", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/482730985430037/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "WPR"}, "launch_date": "2017-09-08", "movement": 0.08}, "10": {"is_unique": true, "name": "Train photo grammar click model on collage data", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/500779143625221/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Photos"}, "launch_date": "2017-10-26", "movement": 0.01}, "13": {"is_unique": true, "name": "iOS SERP GraphQL Batching", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/464490263920776/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-07-24", "movement": 0.05}, "12": {"is_unique": true, "name": "Pc(click|seen, TRUE) model for WPR", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/500601773642958/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "WPR"}, "launch_date": "2017-10-26", "movement": 0.045}, "15": {"is_unique": true, "name": "iOS BEM enable token matching", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/487940854909050/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-09-22", "movement": 0.02}, "14": {"is_unique": true, "name": "Remove grammar for unconnected entities", "scaling_reference": "https://fb.facebook.com/groups/485751768140110/permalink/1607905105924765/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-09-19", "movement": 0.55}, "17": {"is_unique": true, "name": "iOS BEM squashed", "scaling_reference": "https://fburl.com/og8us82l", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-10-05", "movement": 0.04}, "16": {"is_unique": true, "name": "iOS Instant search", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/487647331605069", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-09-14", "movement": 0.02}, "19": {"is_unique": true, "name": "Android BEM delta update", "scaling_reference": "https://fburl.com/ztxo36ku", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-10-19", "movement": 0.045}, "18": {"is_unique": true, "name": "Android BEM squashed", "scaling_reference": "https://fburl.com/w9q1sfaf", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Speed"}, "launch_date": "2017-10-19", "movement": 0.03}, "31": {"is_unique": true, "name": "WWW ensure click logging", "scaling_reference": "https://fburl.com/5ct0cbes", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2017-10-19", "movement": 0.17}, "30": {"is_unique": true, "name": "WWW generate session id on client", "scaling_reference": "https://fburl.com/tlzmohq9", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2017-10-19", "movement": 0.21}, "37": {"is_unique": true, "name": "SERP User Model Refresh + Replace Trending People Boosting Rule with Profile View Count Features", "scaling_reference": "https://fburl.com/nzwi4q5r", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-11-08", "movement": 0.03}, "36": {"is_unique": true, "name": "Middle Name Optionalization for Hard Query", "scaling_reference": "https://fburl.com/mfyc4aiv", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "People"}, "launch_date": "2017-10-31", "movement": 0.05}, "35": {"is_unique": true, "name": "Fixing Accidental Reformulations on Android", "scaling_reference": "https://fb.facebook.com/groups/485751768140110/permalink/1763773850337889/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2018-01-23", "movement": 0.02}, "34": {"is_unique": true, "name": "Adding fblite and mtouch in top line goal", "scaling_reference": "", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2018-01-01", "movement": -1.0}, "33": {"is_unique": true, "name": "Large entity module thumbnail", "scaling_reference": "fburl.com/q5sduufb", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2017-10-04", "movement": -0.04}, "55": {"is_unique": true, "name": "Pages fetching using engagement signals through MSL", "scaling_reference": "https://fburl.com/j8omqtiy", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Pages"}, "launch_date": "2017-09-02", "movement": 0.05}, "32": {"is_unique": true, "name": "Junkiness filtering for connected page", "scaling_reference": "fburl.com/6oba3fzm", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Others"}, "launch_date": "2017-10-11", "movement": -0.09}, "57": {"is_unique": true, "name": "Places High Confidence Module Android", "scaling_reference": "https://fb.facebook.com/groups/1671037496559199/permalink/1946785912317688/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"0": "Places"}, "launch_date": "2018-01-29", "movement": 0.01}, "50": {"is_unique": true, "name": "WPR submodel for Floating Public Posts", "scaling_reference": "https://fb.facebook.com/groups/333778166991987/permalink/522353761467759/", "metric": "search:core:accounting:ratios:click_rate", "teams": {"1": "Posts", "0": "WPR"}, "launch_date": "2017-12-17", "movement": 0.17}}') AS MAP<VARCHAR, MAP<VARCHAR, JSON>>) AS launches\n    ) l CROSS JOIN UNNEST(l.launches) m (k, v)\n), launch_impact_per_team AS (\n    SELECT t.team,\n  \t\tt.n AS team_num,\n      l.*\n    FROM launch_impact l\n        CROSS JOIN UNNEST(teams) WITH ORDINALITY AS t(team, n)\n), launches AS (\n\tSELECT\n  \tteam,\n  \tmovement AS SCR_impact,\n  \tname,\n  \tscaling_reference AS link,\n  \tlaunch_date AS ds,\n  \tteam_num = 1 AS is_included\n  FROM launch_impact_per_team\n  WHERE metric = 'search:core:accounting:ratios:click_rate'\n    AND launch_date >= '2018-01-01'\n), launches_ranked AS (\n\tSELECT *,\n  \tROW_NUMBER() OVER(ORDER BY SCR_impact DESC) AS scr_rank\n  FROM launches\n  WHERE ds >= '2018-01-01'\n)\nSELECT \n\tJSON_FORMAT(CAST(map(array['title', 'link'], array[name, link]) AS JSON)) AS "Launch",\n  *\nFROM launches_ranked\nWHERE IF('Overall' = 'Overall', True, team = 'Overall')
ftw2	prism	mobile	20180308_090430_21420_589r5	presto-cli	SELECT typeof(carrier_id), carrier_id, count(*) FROM (WITH mexico_cities_bing_tiles AS ( SELECT name, locality, CAST(population AS BIGINT) AS population, transform(geometry_to_bing_tiles(ST_GeometryFromText(wkt_string),14), tile -> bing_tile_coordinates(tile) ) AS bing_tiles_14, transform(geometry_to_bing_tiles(ST_GeometryFromText(wkt_string),16), tile -> bing_tile_coordinates(tile) ) AS bing_tiles_16 FROM altan_phase2_cities_polygons ), city_tiles AS ( SELECT name, tile FROM mexico_cities_bing_tiles CROSS JOIN UNNEST(bing_tiles_16) AS t (tile) ), ping_metrics AS ( SELECT BING_TILE_COORDINATES(BING_TILE(SUBSTR(quadkey,4))) AS tile, network_generation, CAST(merge_carrier_id AS VARCHAR) AS carrier_id, CASE WHEN response_body_size <= 14000 THEN 'small' WHEN response_body_size <= 80000 THEN 'medium' ELSE 'large' END AS response_body_size_bucket, CAST(is_fna AS VARCHAR) AS is_fna, CAST(server_hour AS VARCHAR) AS server_hour, CASE WHEN CAST(signal_strength AS BIGINT) <= -105 THEN 'no_service' WHEN CAST(signal_strength AS BIGINT) <= -90 THEN 'poor' WHEN CAST(signal_strength AS BIGINT) <= -73 THEN 'medium' WHEN CAST(signal_strength AS BIGINT) <= -50 THEN 'good' WHEN CAST(signal_strength AS BIGINT) <= 0 THEN 'excellent' ELSE NULL END AS signal_strength_bucket, carrier_country, CASE WHEN ttlb > ttfb -- The 1.0 factor is required to force decimal division\n THEN CAST(CEIL(1.0 * response_body_size / (ttlb - ttfb)) AS BIGINT) * 8 ELSE null END AS dwnld_speed, CASE WHEN response_body_size <= 14000 THEN 'small' WHEN response_body_size <= 80000 THEN 'medium' ELSE 'large' END AS dwnld_speed_size_bucket, CAST( CASE WHEN response_body_size BETWEEN 1500 AND 409600000 AND (ttlb > ttfb) AND ( ( network_generation = '2G' AND (response_body_size / (ttlb - ttfb)) * 8 <= 210.0*1000 ) OR ( network_generation = '3G' AND (response_body_size / (ttlb - ttfb)) * 8 <= 42.0*1000*1000 ) OR ( network_generation = '4G' AND (response_body_size / (ttlb - ttfb)) * 8 <= 300.0*1000*1000 ) ) THEN 1 ELSE 0 END AS TINYINT) AS is_dwnld_speed_clean, rtt, CASE WHEN CAST(rtt AS BIGINT) <= 30 THEN '0-30' WHEN CAST(rtt AS BIGINT) <= 60 THEN '30-60' WHEN CAST(rtt AS BIGINT) <= 90 THEN '60-90' WHEN CAST(rtt AS BIGINT) <= 200 THEN '90-200' WHEN CAST(rtt AS BIGINT) <= 400 THEN '200-400' WHEN CAST(rtt AS BIGINT) <= 800 THEN '400-800' WHEN CAST(rtt AS BIGINT) <= 1600 THEN '800-1600' WHEN CAST(rtt AS BIGINT) <= 3200 THEN '1600-3200' WHEN CAST(rtt AS BIGINT) <= 6400 THEN '3200-6400' WHEN CAST(rtt AS BIGINT) <= 60000 THEN '6400-60000' ELSE '60000-600000' END AS rtt_size_bucket, CAST( CASE WHEN rtt > 0 AND ( ( carrier_country IN ('US', 'DE', 'GB', 'FR', 'IT', 'KR', 'JP', 'AU', 'CA') AND rtt <= 10000 ) OR ( carrier_country NOT IN ('US', 'DE', 'GB', 'FR', 'IT', 'KR', 'JP', 'AU', 'CA') AND rtt <= 600000 ) ) THEN 1 ELSE 0 END AS TINYINT) AS is_rtt_clean, CAST(signal_strength AS BIGINT) AS signal_strength, CASE WHEN CAST(signal_strength AS BIGINT) <= -105 THEN 'no_service' WHEN CAST(signal_strength AS BIGINT) <= -90 THEN 'poor' WHEN CAST(signal_strength AS BIGINT) <= -73 THEN 'medium' WHEN CAST(signal_strength AS BIGINT) <= -50 THEN 'good' WHEN CAST(signal_strength AS BIGINT) <= 0 THEN 'excellent' ELSE NULL END AS signal_strength_size_bucket, CAST( CASE WHEN CAST(signal_strength AS DOUBLE) < 0 THEN 1 ELSE 0 END AS TINYINT) AS is_signal_strength_clean, 2018-03-05 AS ds FROM ( SELECT *, CASE WHEN carrier_id=39682751744 THEN 32525745814 ELSE carrier_id END AS merge_carrier_id FROM cell_tower_info_clean_tdo WHERE ds = '2018-03-05' AND tower_changed = 'false' AND connection_type = 'mobile' AND carrier_country = country AND country = 'MX' ) T WHERE TRUE --merge_carrier_id IN (12075527549, 21428283450, 881655265215717)\n), tile_samples AS ( SELECT COALESCE(ping_metrics.tile, city_tiles.tile) AS tile, name, carrier_id, network_generation, IF(is_dwnld_speed_clean=1, dwnld_speed, NULL) AS dwnld_speed, IF(is_rtt_clean=1, rtt, NULL) AS rtt, IF(is_signal_strength_clean=1, signal_strength, NULL) AS signal_strength FROM ping_metrics INNER JOIN city_tiles USING(tile) ) SELECT name, carrier_id, network_generation, COUNT(*) AS sample_count, AVG(dwnld_speed) AS avg_dwnld_speed, APPROX_PERCENTILE(dwnld_speed, 0.50) AS p50_dwnld_speed, APPROX_PERCENTILE(dwnld_speed, 0.95) AS p95_dwnld_speed, AVG(rtt) AS avg_rtt, APPROX_PERCENTILE(rtt, 0.50) AS p50_rtt, APPROX_PERCENTILE(rtt, 0.95) AS p95_rtt, AVG(signal_strength) AS avg_signal_strength, APPROX_PERCENTILE(signal_strength, 0.50) AS p50_signal_strength, APPROX_PERCENTILE(signal_strength, 0.95) AS p95_signal_strength FROM tile_samples GROUP BY 1,2,3 ORDER BY 1,2,3) GROUP BY 1,2 ORDER BY 1\n
de4atn3	raptor	de	20180328_231121_33532_gr9jq	unidash:203452556907996:argus:509073	SELECT\n    ds,\n    a.label_name,\n    1.0 * SUM(a.media_creation_count) / SUM(b.media_creation_count) AS p_media_label\nFROM (\n    SELECT\n        ds,\n        media_group,\n        media_type,\n        platform,\n        source,\n        CASE WHEN overall_country IN ('US', 'CA', 'GB', 'BR', 'KR', 'FR', 'DE', 'JP', 'AU') THEN 'FCI' ELSE 'non-FCI' END AS is_fci,\n        CASE WHEN ig_lifestage IN ('early_high_school', 'late_high_school') THEN 'teen' ELSE ig_lifestage END as lifestage,\n        label_name,\n        SUM(media_creation_count) as media_creation_count\n    FROM agg_ig_xray_media\n    WHERE label_name != 'overall'\n    GROUP BY 1, 2, 3, 4, 5, 6, 7, 8\n) a\nJOIN (\n    SELECT\n        ds,\n        media_group,\n        media_type,\n        platform,\n        source,\n        CASE WHEN overall_country IN ('US', 'CA', 'GB', 'BR', 'KR', 'FR', 'DE', 'JP', 'AU') THEN 'FCI' ELSE 'non-FCI' END AS is_fci,\n        CASE WHEN ig_lifestage IN ('early_high_school', 'late_high_school') THEN 'teen' ELSE ig_lifestage END as lifestage,\n        label_name,\n        SUM(media_creation_count) as media_creation_count\n    FROM agg_ig_xray_media\n    WHERE label_name = 'overall'\n    GROUP BY 1, 2, 3, 4, 5, 6, 7, 8\n) b USING (ds, media_group, media_type, platform, source, is_fci, lifestage)\n\nWHERE 1 = 1\n   AND media_group = 'feed'\n   AND is_fci = 'FCI'\n   AND lifestage = 'teen'\n\nGROUP BY 1, 2 ORDER BY 1, 2
ftw2_batch3	prism_batch	si	20180330_151017_30951_jtkgt	dataswarm@worker@si.abusive_groups.groups_strike_tracker.final	/* Generated */\nINSERT INTO groups_reports_strikes_tracker (\n  "group_id",\n  "num_posts",\n  "num_all_deletions",\n  "num_relevant_deletions",\n  "num_reported_content",\n  "num_total_content_reports",\n  "pct_all_deletions",\n  "pct_relevant_deletions",\n  "pct_reports",\n  "major_inferred_violation",\n  "deletion_hist",\n  "relevant_deletion_hist",\n  "content_report_hist",\n  "major_content_report_type",\n  "num_holistic_reports",\n  "holistic_report_hist",\n  "major_holistic_report_type",\n  "ds"\n)\nSELECT\n  "group_id",\n  "num_posts",\n  "num_all_deletions",\n  "num_relevant_deletions",\n  "num_reported_content",\n  "num_total_content_reports",\n  "pct_all_deletions",\n  "pct_relevant_deletions",\n  "pct_reports",\n  "major_inferred_violation",\n  "deletion_hist",\n  "relevant_deletion_hist",\n  "content_report_hist",\n  "major_content_report_type",\n  "num_holistic_reports",\n  "holistic_report_hist",\n  "major_holistic_report_type",\n  '2018-03-28' AS "ds"\nFROM (\n  /* User-provided */\n  WITH strikes AS (\n      SELECT\n          group_id\n          , num_posts\n          , deletion_hist\n          , relevant_deletion_hist\n          , num_all_deletions\n          , pct_all_deletions\n          , num_relevant_deletions\n          , pct_relevant_deletions\n          , major_inferred_violation\n      FROM\n          groups_strikes_tracker\n      WHERE\n          ds='2018-03-28'\n  ),\n  reports AS (\n      SELECT\n           group_id\n          , num_total_content_reports\n          , num_reported_content\n          , content_report_hist\n          , num_holistic_reports\n          , holistic_report_hist\n      FROM\n          groups_reports_tracker\n      WHERE\n          ds='2018-03-28'\n  )\n  SELECT\n      t1.group_id\n      , COALESCE(t1.num_posts, 0.0) AS num_posts\n      , COALESCE(t1.num_all_deletions, 0.0) AS num_all_deletions\n      , COALESCE(t1.num_relevant_deletions, 0.0) AS num_relevant_deletions\n      , COALESCE(t2.num_reported_content, 0.0) AS num_reported_content\n      , COALESCE(t2.num_total_content_reports, 0.0) AS num_total_content_reports\n      , COALESCE(t1.pct_all_deletions, 0.0) AS pct_all_deletions\n      , COALESCE(t1.pct_relevant_deletions, 0.0) AS pct_relevant_deletions\n      , ROUND(COALESCE(t2.num_reported_content, 0.0)/\n              t1.num_posts,3) AS pct_reports\n      , t1.major_inferred_violation\n      , t1.deletion_hist\n      , t1.relevant_deletion_hist\n      , t2.content_report_hist\n      , TRY(MAP_KEYS(\n          MAP_FILTER(\n              t2.content_report_hist\n              , (k, v) -> v = ARRAY_MAX(MAP_VALUES(content_report_hist))\n          )\n        )[1]) AS major_content_report_type\n      , COALESCE(t2.num_holistic_reports, 0.0) AS num_holistic_reports\n      , t2.holistic_report_hist\n      , TRY(MAP_KEYS(\n          MAP_FILTER(\n              t2.holistic_report_hist\n              , (k, v) -> v = ARRAY_MAX(MAP_VALUES(holistic_report_hist))\n          )\n        )[1]) AS major_holistic_report_type\n  FROM strikes t1\n  LEFT JOIN reports t2\n  USING (group_id)\n)
carbon_batch	prism_batch	operations	20180401_015644_07362_di6ar	dataswarm@worker@operations.co_quality.r42_market_metrics_postman.load_data[TURKISH]	WITH base_metrics AS (\n\n    SELECT\n        ds,\n        market_reporting ,\n        TRIM(queue_name) queue_name,\n        metric_name,\n        SUM(metric_value) metric_value\n    FROM\n        fct_job_summary_daily\n    WHERE\n        ds IN ('2018-03-29','2018-03-30')\n        AND market_reporting = 'TURKISH'\n        AND known_bug = 0\n        AND metric_name IN (\n            'intr_ers_close_on_time_cnt',\n            'intr_ers_close_cnt',\n            'inventory_late_cnt',\n            'intr_ers_incoming_non_dupe_cnt'\n        )\n    GROUP BY 1,2,3,4\n),\n\ndaily_metrics_organized AS (\n\n    SELECT DISTINCT\n        a.ds,\n        a.market_reporting,\n        a.queue_name,\n        CASE WHEN b.metric_name = 'intr_ers_incoming_non_dupe_cnt' THEN b.metric_value END incoming_non_dupe_cnt,\n        CASE WHEN b.metric_name = 'intr_ers_close_cnt' THEN b.metric_value END closed,\n        CASE WHEN b.metric_name = 'intr_ers_close_on_time_cnt' THEN b.metric_value END closed_on_time,\n        CASE WHEN b.metric_name = 'intr_ers_close_cnt' THEN b.metric_value END -\n        CASE WHEN a.metric_name = 'intr_ers_close_on_time_cnt' THEN a.metric_value END closed_late,\n        CASE WHEN b.metric_name = 'inventory_late_cnt' THEN b.metric_value END late_inventory\n    FROM base_metrics a\n        JOIN base_metrics b\n        USING (ds, market_reporting , queue_name)\n    WHERE a.ds = '2018-03-30'\n),\n\ndod_variance AS (\n\n    SELECT DISTINCT\n        '2018-03-30' ds, a.market_reporting, a.queue_name,\n        CASE WHEN b.ds = '2018-03-30' THEN b.metric_value END /\n        CASE WHEN a.ds = '2018-03-29' THEN a.metric_value END -1 dod_variance_perc\n\n    FROM base_metrics a\n        JOIN base_metrics b\n        USING (market_reporting , queue_name, metric_name )\n    WHERE a.metric_name = 'intr_ers_incoming_non_dupe_cnt'\n)\n\nSELECT\n    a.market_reporting, a.queue_name,\n    COALESCE(MAX(closed),0) closed,\n    COALESCE(MAX(closed_on_time),0) closed_on_time,\n    COALESCE(MAX(closed_late),0) closed_late,\n    COALESCE(MAX(late_inventory),0) late_inventory,\n    COALESCE(MAX(incoming_non_dupe_cnt),0) incoming_non_dupe_cnt,\n    COALESCE(ROUND(MAX(b.dod_variance_perc) * 100,2),0) dod_variance_perc,\n    a.ds\nFROM daily_metrics_organized a\n    JOIN dod_variance b\n    USING (ds, market_reporting , queue_name)\n\nGROUP BY 1,2,9
atn3_batch4	prism_batch	infrastructure	20180327_071415_16644_yrzjx	dataswarm@worker@infrastructure.oculus_metrics.ocpac_explore.ocpac_explore_core1	/* Generated */\nINSERT INTO ocpac_explore_core1 (\n  "task_number",\n  "task_activity_time",\n  "task_created_time",\n  "status",\n  "tags_match1",\n  "tags_match2",\n  "incl_match_crit2",\n  "tag_exclusions1",\n  "tag_exclusions2",\n  "task_priority",\n  "ds"\n)\nSELECT\n  "task_number",\n  "task_activity_time",\n  "task_created_time",\n  "status",\n  "tags_match1",\n  "tags_match2",\n  "incl_match_crit2",\n  "tag_exclusions1",\n  "tag_exclusions2",\n  "task_priority",\n  '2018-03-27' AS "ds"\nFROM (\n  /* User-provided */\n  -- ====================================================================\n  -- ====================================================================\n  -- 2018-03-07 @ 16:05\n  -- ---------------------------------- \n  -- Explore\n  -- CORE 1\n  -- ----------------------------------\n\n\n                   -- ===================================================================== \n                   -- Re-establish the metadata needed for this phase of analysis\n                   --\n  WITH params     (  period, stop_varchar,  stop_date,  stop_unixtime, period_seconds, ds_source\n                   , burndown_start, target_burndown, burndown_eval_period_days\n                   , incl_tags1, NbrToIncl1, incl_match_crit1, incl_tags2, NbrToIncl2, incl_match_crit2\n                   , excl_tags1, NbrToExcl1, excl_match_crit1, excl_tags2, NbrToExcl2, excl_match_crit2\n                   , priorities_sought, time_range_4_priorities_set\n                   , tags_for_time_check, timed_tags_match_crit, time_range_4_tags_set)\n                   --\n       AS         (SELECT period\n                        , stop_varchar\n                        , CAST(stop_varchar AS DATE) AS stop_date\n                        , stop_unixtime\n                        , period_seconds\n                        , ds_source\n                     --\n                        , burndown_start\n                        , target_burndown\n                        , burndown_eval_period_days\n                     --\n                        , incl_tags1\n                        , NbrToIncl1\n                        , incl_match_crit1\n                     --\n                        , incl_tags2\n                        , NbrToIncl2\n                        , incl_match_crit2\n                     --\n                        , excl_tags1\n                        , NbrToExcl1\n                        , excl_match_crit1\n                     --\n                        , excl_tags2\n                        , NbrToExcl2\n                        , excl_match_crit2\n                     --\n                        , priorities_sought\n                        , time_range_4_priorities_set\n                     --\n                        , tags_for_time_check\n                        , timed_tags_match_crit\n                        , time_range_4_tags_set\n                     --\n                   FROM   ocpac_explore_params\n                   WHERE  ds = '2018-03-27'\n                  )  \n                   -- SELECT * FROM params /*\n  --\n  -- -----------------------------------------------------------------------\n  -- -----------------------------------------------------------------------\n                  --\n                  --\n                  --  This is the first (innermost) part of the core query,\n                  --  querying tasks_history as this table has a concise listing of all tags ever used with a task\n                  -- \n                  -- AND for some as-yet unclear reason, skipping the join based on this tasks_history query will\n                  --   cause too many records being returned if using only tasks_activity.\n                  --\n     , core0a     (task_number)\n       AS         (SELECT DISTINCT  th1.task_number\n                       FROM   tasks_history th1\n                       JOIN   params p\n                         ON   CASE incl_match_crit1 WHEN 'AND' THEN (CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags1, task_tags) ) = NbrToIncl1 THEN True ELSE False END)\n                                                    WHEN 'OR'  THEN (CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags1, task_tags) ) >= 1         THEN True ELSE False END) END\n                        AND   CASE incl_match_crit2 WHEN ''    THEN True\n                                                    WHEN 'AND' THEN (CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags2, task_tags) ) = NbrToIncl2 THEN True ELSE False END)\n                                                    WHEN 'OR'  THEN (CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags2, task_tags) ) >= 1         THEN True ELSE False END) END\n                       WHERE  th1.ds = '2018-03-25'\n                      ) -- select * from core0 /*\n\n                  --\n                  --\n                  -- This query on tasks_activity extracts the data needed for all subsequent work,\n                  -- early on denoting statuses for each task change event\n                  --\n\n\n    , core0b         (task_number, task_activity_time, task_created_time, status, tags_match1, tags_match2, incl_match_crit2, tag_exclusions1, tag_exclusions2, task_priority)\n      AS             (SELECT DISTINCT\n                             task_number\n                           , task_updated_time                                                                                                                                            AS task_activity_time\n                           , task_created_time\n                           , CASE WHEN task_completed_time = 0 THEN 'OPEN' ELSE 'CLOSED' END                                                                                              AS status \n                        --\n                           , CASE WHEN incl_match_crit1 = ''    THEN 'NO'\n                                  WHEN incl_match_crit1 = 'AND' THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags1, task_tags ) )  = NbrToIncl1 THEN 'YES' ELSE 'NO' END)\n                                  WHEN incl_match_crit1 = 'OR'  THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags1, task_tags ) ) >= 1          THEN 'YES' ELSE 'NO' END) END       AS tags_match1\n                        --\n                           , CASE WHEN incl_match_crit2 = ''    THEN 'NO'\n                                  WHEN incl_match_crit2 = 'AND' THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags2, task_tags ) )  = NbrToIncl2 THEN 'YES' ELSE 'NO' END)\n                                  WHEN incl_match_crit2 = 'OR'  THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(incl_tags2, task_tags ) ) >= 1          THEN 'YES' ELSE 'NO' END) END       AS tags_match2\n                        --\n                           , incl_match_crit2\n                        --\n                           , CASE WHEN excl_match_crit1 = ''    THEN 'KEEP' \n                                  WHEN excl_match_crit1 = 'AND' THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(excl_tags1, task_tags ) ) = NbrToExcl1 THEN 'EXCLUDE' ELSE 'KEEP' END )\n                                  WHEN excl_match_crit1 = 'OR'  THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(excl_tags1, task_tags ) ) > 0          THEN 'EXCLUDE' ELSE 'KEEP' END ) END AS tag_exclusions1\n                        --\n                           , CASE WHEN excl_match_crit2 = ''    THEN 'KEEP' \n                                  WHEN excl_match_crit2 = 'AND' THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(excl_tags2, task_tags ) ) = NbrToExcl2 THEN 'EXCLUDE' ELSE 'KEEP' END )\n                                  WHEN excl_match_crit2 = 'OR'  THEN ( CASE WHEN CARDINALITY( ARRAY_INTERSECT(excl_tags2, task_tags ) ) > 0          THEN 'EXCLUDE' ELSE 'KEEP' END ) END AS tag_exclusions2\n                        --\n                           , CASE task_priority WHEN 0 THEN 'UNASSIGNED' WHEN 1 THEN 'UNBREAK NOW!' WHEN 2 THEN 'HIGH' WHEN 3 THEN 'MEDIUM' WHEN 4 THEN 'LOW' WHEN 5 THEN 'WISHLIST'  END AS task_priority\n                      FROM   tasks_activity\n                         ,   params     p1\n                     )\n                     -- select * from core0b order by task_number, task_activity_time  /*\n                     -- \n                     -- \n                     -- \n                     -- \n    , core1          (task_number, task_activity_time, task_created_time, status, tags_match1, tags_match2, incl_match_crit2, tag_exclusions1, tag_exclusions2, task_priority)\n      AS             (SELECT DISTINCT \n                             b.task_number\n                           , task_activity_time\n                           , task_created_time\n                           , status\n                           , tags_match1,        tags_match2\n                           , incl_match_crit2\n                           , tag_exclusions1,    tag_exclusions2\n                           , task_priority\n                      FROM   core0b        b\n                      JOIN   core0a        a\n                        ON   a.task_number = b.task_number\n                     )\n                   -- select * from core1 /*\n  --\n  -- -----------------------------------------------------------------------\n  -- -----------------------------------------------------------------------\n  -- -----------------------------------------------------------------------\n  --\n  --\n  -- RESULTS IN TABLE:  CORE 1\n  -- RESULTS IN TABLE:  ocpac_explore_core1\n  --\n\n  SELECT task_number\n       , task_activity_time\n       , task_created_time\n       , status\n       , tags_match1,       tags_match2\n       , incl_match_crit2\n       , tag_exclusions1,   tag_exclusions2\n       , task_priority\n  FROM   core1\n\n\n  -- -----------------------------------------------------------------------\n  -- CORE 1 END SQL\n  -- -----------------------------------------------------------------------\n\n\n  /*\n  */\n  -- ====================================================================\n  -- ====================================================================\n  -- ====================================================================\n)
snc1_batch	prism_batch	si	20180308_140749_43902_afybh	dataswarm@worker@si.co_igops.offline_classifiers.post_queue_classifiers.pipelines[POST_INDIAN_SS].subtasks[create_feature_table]	/* Generated */\nINSERT INTO stg_classifier_post_indian_ss_scores (\n  "features",\n  "ds"\n)\nSELECT\n  "features",\n  '2018-03-07' AS "ds"\nFROM (\n  /* User-provided */\n  WITH jobs AS (\n  SELECT\n      job_id id,\n      queue_id,\n      IF(\n          REGEXP_LIKE(\n              JSON_EXTRACT_SCALAR(\n                  decision_data,\n                  '$.decision_string'\n              ),\n              '[Ii]gnore'\n          ),\n          'false',\n          'true'\n      ) is_actioned,\n      JSON_EXTRACT_SCALAR(\n          decision_data,\n          '$.decision_string'\n      ) decision\n  FROM fct_job_event:operations\n  WHERE ds = '2018-03-07'\n  AND co_system = 'SRT'\n  AND event = 'close'\n  AND review_system <> 'automation'\n  AND queue_id IN (597055187106338)\n  )\n\n  SELECT\n      JSON_FORMAT(CAST(\n          MAP(\n              ARRAY[\n                  'id',\n                  'queue_id',\n                  'is_actioned',\n                  'decision',\n                  'text'\n              ],\n              ARRAY[\n                  CAST(id AS VARCHAR),\n                  CAST(queue_id AS VARCHAR),\n                  is_actioned,\n                  decision,\n                  text\n              ]\n          )\n          AS JSON\n      )) features\n  FROM (\n      SELECT\n          srt.id,\n          srt.is_actioned,\n          srt.decision,\n          srt.queue_id,\n          REDUCE(\n              MAP_VALUES(\n                  MAP_FILTER(\n                      CAST(JSON_PARSE(dim.job_data) AS MAP<VARCHAR,VARCHAR>),\n                      (k, v) -> k IN ('title','text','description')\n                  )\n              ),\n              '',\n              (i, n) -> CONCAT(i, ' ', n),\n              i -> i\n          ) text\n      FROM dim_single_review_jobs:di dim\n      JOIN jobs srt\n      USING (id, queue_id)\n      WHERE dim.ds = '2018-03-07'\n      AND dim.queue_id IN (597055187106338)\n  )\n)
